{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "TestLoader.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW6VWCHjm-g6",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tMQ3_yDj_md",
        "colab_type": "code",
        "outputId": "f548da9a-9902-4968-f128-4c57768e04c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp /content/gdrive/My\\ Drive/data/*.zip .\n",
        "!unzip /content/sudoku.zip\n",
        "!mkdir /content/test\n",
        "!unzip /content/sudoku_test.zip -d /content/test\n",
        "!mv /content/test/sudoku.csv /content/sudoku_test.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Archive:  /content/sudoku.zip\n",
            "  inflating: sudoku.csv              \n",
            "Archive:  /content/sudoku_test.zip\n",
            "  inflating: /content/test/sudoku.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cghus0djA4Q",
        "colab_type": "code",
        "outputId": "d1dd0461-b110-4717-fe73-115197eb1214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!rm -rf drl-sudoku\n",
        "!git clone https://github.com/cloughurd/drl-sudoku.git\n",
        "!mv drl-sudoku/data/* ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'drl-sudoku'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 338 (delta 3), reused 9 (delta 2), pack-reused 326\u001b[K\n",
            "Receiving objects: 100% (338/338), 974.53 KiB | 23.20 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaIypeXinqFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import math\n",
        "import contextlib\n",
        "from typing import List, Tuple\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from model_util import stacked_to_mono, count_params\n",
        "\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFMABO1nnB7f",
        "colab_type": "text"
      },
      "source": [
        "# Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxiPBreTi7Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataloader import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqQdT8QAnZXa",
        "colab_type": "text"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1WF_WlwqVlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJM42t58rc79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToSudokuRange(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ToSudokuRange, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.net = lambda x: (9 * self.sigmoid(x)) + 0.5\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MecL5K3ielK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SolverLayer(nn.Module):\n",
        "  def __init__(self, in_filters:int, hidden_filters:int, out_filters:int, convtranspose:bool=True):\n",
        "    super(SolverLayer, self).__init__()\n",
        "\n",
        "    if in_filters != out_filters:\n",
        "      self.skip = nn.Conv2d(in_filters, out_filters, kernel_size=1)\n",
        "    else:\n",
        "      self.skip = nn.Identity()\n",
        "\n",
        "    self.initial_normalization = nn.InstanceNorm2d(in_filters) # Normalize every individual game within its filters. Not positive this is a good idea... maybe use the 3d version?\n",
        "\n",
        "    self.HorizontalDependencies = self._get_dependency_module(in_filters, hidden_filters, (9,1), convtranspose=convtranspose)\n",
        "    self.VerticalDependencies = self._get_dependency_module(in_filters, hidden_filters, (1,9), convtranspose=convtranspose)\n",
        "    self.QuadrantDependencies = self._get_dependency_module(in_filters, hidden_filters, (3, 3), stride=3, convtranspose=convtranspose)\n",
        "\n",
        "    num_hidden = hidden_filters * 3\n",
        "    \n",
        "    self.Reduce = nn.Sequential(\n",
        "        nn.Conv2d(num_hidden, num_hidden, kernel_size=(3, 3), padding=1),\n",
        "        nn.Conv2d(num_hidden, out_filters, kernel_size=(1, 1)), # Look at each cell only, without neighbors; neighbors have already been considered.\n",
        "        nn.LeakyReLU()\n",
        "    )\n",
        "\n",
        "    self.Final = nn.LeakyReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    skip = self.skip(x)\n",
        "    x = self.initial_normalization(x)\n",
        "    horizontal_result = self.HorizontalDependencies(x)\n",
        "    vertical_result = self.VerticalDependencies(x)\n",
        "    quadrant_result = self.QuadrantDependencies(x)\n",
        "\n",
        "    combined = torch.cat((horizontal_result, vertical_result, quadrant_result), dim=1)\n",
        "\n",
        "    reduced = self.Reduce(combined)\n",
        "\n",
        "    residualized = reduced + skip\n",
        "    return self.Final(residualized)\n",
        "\n",
        "  def _get_dependency_module(self, in_filters, hidden_filters, kernel_size, stride=None, convtranspose=False):\n",
        "    if stride is None:\n",
        "      stride = 1\n",
        "      \n",
        "    if convtranspose:\n",
        "        return nn.Sequential(\n",
        "          nn.Conv2d(in_filters, hidden_filters*9, kernel_size=kernel_size, stride=stride),\n",
        "          nn.BatchNorm2d(hidden_filters*9),\n",
        "          nn.LeakyReLU(),\n",
        "          nn.ConvTranspose2d(hidden_filters*9, hidden_filters, kernel_size=kernel_size, stride=stride),\n",
        "          nn.BatchNorm2d(hidden_filters),\n",
        "          nn.Dropout(),\n",
        "          nn.LeakyReLU()\n",
        "      )\n",
        "    else:\n",
        "      return nn.Sequential(\n",
        "          nn.Conv2d(in_filters, hidden_filters, kernel_size=kernel_size, stride=stride),\n",
        "          nn.BatchNorm2d(hidden_filters),\n",
        "          nn.LeakyReLU(),\n",
        "          Reshape((-1, hidden_filters, 9)),\n",
        "          # Make into a full board shape that can be recombined... Maybe?\n",
        "          nn.Linear(9, 81), \n",
        "          nn.BatchNorm1d(hidden_filters),\n",
        "          nn.Dropout(),\n",
        "          Reshape((-1, hidden_filters, 9, 9)),\n",
        "          nn.LeakyReLU()\n",
        "      )\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG34hwOxnY74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MonoModel(nn.Module):\n",
        "  def __init__(self, solver_depth:int, convtranspose:bool=True, use_to_sudoku_range=True, growth_rate:Tuple[int]=(3,9)):\n",
        "    super(MonoModel, self).__init__()\n",
        "    if type(growth_rate) == int:\n",
        "      growth_base = 3\n",
        "      growth_frequency = growth_rate\n",
        "    else:\n",
        "      growth_base, growth_frequency = growth_rate\n",
        "    layer_numbers = [(growth_base**(i // growth_frequency + 2), growth_base**( (i+1) // growth_frequency + 2)) for i in range(solver_depth - 2)]\n",
        "    print(layer_numbers)\n",
        "    reducer_layer = layer_numbers[-1][1]\n",
        "    self.net = nn.Sequential(\n",
        "        SolverLayer(1, 9, 9, convtranspose=convtranspose),\n",
        "        *[ SolverLayer(i, i, o, convtranspose=convtranspose) for i, o in layer_numbers],\n",
        "        SolverLayer(reducer_layer, reducer_layer, 1, convtranspose=convtranspose),\n",
        "        Reshape((-1, 1, 9, 9)),\n",
        "        ToSudokuRange() if use_to_sudoku_range else nn.Identity()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3QgEnxzop79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StackedModel(nn.Module):\n",
        "  def __init__(self, solver_depth:int, convtranspose:bool=True, growth_rate:Tuple[int]=(3,9)):\n",
        "    super(StackedModel, self).__init__()\n",
        "    if type(growth_rate) == int:\n",
        "      growth_base = 3\n",
        "      growth_frequency = growth_rate\n",
        "    else:\n",
        "      growth_base, growth_frequency = growth_rate\n",
        "    layer_numbers = [(growth_base**(i // growth_frequency + 2), growth_base**( (i+1) // growth_frequency + 2)) for i in range(solver_depth - 1)]\n",
        "    print(layer_numbers)\n",
        "    reducer_layer = layer_numbers[-1][1]\n",
        "    self.net = nn.Sequential(\n",
        "        *[ SolverLayer(i, i, o, convtranspose=convtranspose) for i, o in layer_numbers],\n",
        "        SolverLayer(reducer_layer, reducer_layer, 9, convtranspose=convtranspose),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_A2vsv3q76T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def puzzle_exactifier(p):\n",
        "  return torch.round(p)\n",
        "\n",
        "\n",
        "\n",
        "def puzzle_masker(attempts, starting_puzzles):\n",
        "  assert attempts.size() == starting_puzzles.size()\n",
        "  num_filled_in_solution = torch.sum(starting_puzzles != 0).item()\n",
        "  attempts = torch.where(starting_puzzles == 0, attempts, starting_puzzles)\n",
        "  return (attempts, starting_puzzles, num_filled_in_solution)\n",
        "\n",
        "def solved_accuracy(attempts, solutions, starting_puzzles):\n",
        "  # print(f\"Puzzle Acc Before if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  if len(attempts.size()) == 4 and attempts.size(1) == 9:\n",
        "    attempts = stacked_to_mono(attempts).squeeze(1)\n",
        "    starting_puzzles = stacked_to_mono(starting_puzzles).squeeze(1)\n",
        "    solutions = solutions + 1\n",
        "  # print(f\"After if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  assert attempts.size() == solutions.size()\n",
        "  masked_puzzle, _, _ = puzzle_masker(attempts, starting_puzzles)\n",
        "  # print(masked_puzzle, solutions, starting_puzzles)\n",
        "  num_puzzles = attempts.size(0)\n",
        "  num_correct = (masked_puzzle.eq(solutions).sum(1).sum(1) == 9).sum().item()\n",
        "  # if num_correct > 0:\n",
        "    # print(\"\\n-Masked - \\n\", masked_puzzle, \"\\n- Solutions -\\n\", solutions)\n",
        "  return num_correct / num_puzzles\n",
        "\n",
        "def cell_accuracy(attempts, solutions, starting_puzzles):\n",
        "  # print(f\"Cell Acc Before if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  if len(attempts.size()) == 4 and attempts.size(1) == 9:\n",
        "    attempts = stacked_to_mono(attempts)\n",
        "    starting_puzzles = stacked_to_mono(starting_puzzles)\n",
        "    solutions = solutions + 1\n",
        "  # print(f\"After if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  assert attempts.size() == solutions.size()\n",
        "  masked_puzzle, _, num_filled = puzzle_masker(attempts, starting_puzzles)\n",
        "  print(\"\\nAttempts:\\n\", attempts, \"\\nMasked\\n\", masked_puzzle, \"\\nInitial\\n\", starting_puzzles, \"\\nSolution\\n\", solutions)\n",
        "  num_cells = attempts.numel()\n",
        "  print(f\"Comparison: \\n{masked_puzzle.eq(solutions)}\")\n",
        "  num_correct = masked_puzzle.eq(solutions).sum().item()\n",
        "  num_guessed_correctly = num_correct - num_filled\n",
        "  num_to_guess = num_cells - num_filled\n",
        "  # print(f\"--- {num_cells} - {num_correct} - {num_cells} - {num_filled} ---\")\n",
        "  return num_guessed_correctly / num_to_guess\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiPAmV3Eq5vi",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu-uveXztc8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_out(save_loc:str, model:MonoModel, **kargs):\n",
        "  if save_loc is None:\n",
        "    print(\"Skipping save, no save_loc provided.\")\n",
        "    return\n",
        "  else:\n",
        "    print(f\"Saving to {save_loc}\")\n",
        "  state = {\n",
        "      \"model\": model.state_dict()\n",
        "  }\n",
        "\n",
        "  for k, v in kargs.items():\n",
        "    state[k]=v\n",
        "  \n",
        "  torch.save(state, save_loc)\n",
        "\n",
        "def train(model:MonoModel,\n",
        "          criterion:torch.nn.modules.loss._Loss,\n",
        "          optimizer:torch.optim.Optimizer,\n",
        "          train_loader:DataLoader,\n",
        "          valid_loader:DataLoader,\n",
        "          num_epochs:int,\n",
        "          valid_frequency:int=5,\n",
        "          save_interval:int=1000,\n",
        "          mono=True,\n",
        "          save_loc:str=None):\n",
        "  loop = tqdm(total=num_epochs * len(train_loader) + (num_epochs // valid_frequency) * len(valid_loader), position=0)\n",
        "\n",
        "  # The loss of the last training and validation iteration, respectively.  \n",
        "  train_loss = None\n",
        "  valid_loss = None\n",
        "\n",
        "  # The puzzle accuracy of the last training and validation itersions. ( # puzzles right / # puzzles total )\n",
        "  train_accuracy = None\n",
        "  valid_accuracy = None\n",
        "\n",
        "  # The cell accuracy of the last training and validation iterations ( # filled cells right / # num fillable cells )\n",
        "  train_inner_acc = None\n",
        "  valid_inner_acc = None\n",
        "\n",
        "  tot_training_losses = []\n",
        "  tot_training_accuracies = []\n",
        "  tot_training_cell_accuracies = []\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "\n",
        "    training_losses = []\n",
        "    training_accuracies = []\n",
        "    training_cell_accuracies = []\n",
        "\n",
        "    loop.set_description(f\"[Training] Epoch: {e}. Loss: {valid_loss}/{train_loss}. Total Accuracy: {train_accuracy}/{valid_accuracy}. Inner Accuracy: {train_inner_acc}/{valid_inner_acc}\")\n",
        "\n",
        "    for i, (puzzle, solution) in enumerate(train_loader):\n",
        "      if mono:\n",
        "        puzzle, solution = puzzle.float().cuda(async=False), (solution.float() + 1).cuda(async=False).unsqueeze(1)\n",
        "      else:\n",
        "        puzzle, solution = puzzle.float().cuda(async=False), solution.long().cuda(async=False)\n",
        "\n",
        "      # print(f\"\\nPuzzle: {puzzle.size()}; solution: {solution.size()}\")\n",
        "      # initial_puzzle = puzzle.clone()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      attempt = model(puzzle)\n",
        "\n",
        "      if mono:\n",
        "        loss = criterion(attempt, solution)\n",
        "      else:\n",
        "        solution_in = solution.view(-1, 81)\n",
        "        attempt_in = attempt.view(-1, 9, 81)\n",
        "        loss = criterion(attempt_in, solution_in)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss = loss.item()\n",
        "      training_losses.append(train_loss)\n",
        "\n",
        "      # Compute accuracies\n",
        "      exactified = puzzle_exactifier(attempt)\n",
        "\n",
        "      solve_accuracy = solved_accuracy(exactified, solution, puzzle)\n",
        "      c_acc = cell_accuracy(exactified, solution, puzzle)\n",
        "\n",
        "      train_accuracy = solve_accuracy\n",
        "      training_accuracies.append(train_accuracy)\n",
        "\n",
        "      train_inner_acc = c_acc\n",
        "      training_cell_accuracies.append(train_inner_acc)\n",
        "\n",
        "      loop.set_description(f\"[Training] Epoch: {e}. Loss: {valid_loss}/{train_loss}. Total Accuracy: {valid_accuracy}/{train_accuracy}. Inner Accuracy: {train_inner_acc}/{valid_inner_acc}\")\n",
        "      loop.update()\n",
        "\n",
        "      if i % save_interval == 0:\n",
        "        tmp_losses = tot_training_losses + [training_losses]\n",
        "        tmp_game_accs = tot_training_accuracies + [training_accuracies]\n",
        "        tmp_cell_accs = tot_training_cell_accuracies + [training_cell_accuracies]\n",
        "        save_out(save_loc, model, train_loss=tmp_losses, train_game_accs=tmp_game_accs, train_cell_accs=tmp_cell_accs, epoch=e, iteration=i)\n",
        "    tot_training_losses.append(training_losses)\n",
        "    tot_training_accuracies.append(training_accuracies)\n",
        "    tot_training_cell_accuracies.append(training_cell_accuracies)\n",
        "    save_out(save_loc, model, train_loss=tot_training_losses, train_game_accs=tot_training_accuracies, train_cell_accs=tot_training_cell_accuracies, epoch=e, iteration=-1)\n",
        "  return model, tot_training_losses, tot_training_accuracies, tot_training_cell_accuracies\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRJwXojO6QGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MonoModel(solver_depth=5).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "train_loader = get_loader(root=\"/content/\", batch_size=3, mono=True, train=True, cap_train=5120)\n",
        "valid_loader = []\n",
        "num_epochs = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlGR35vHqScP",
        "colab_type": "code",
        "outputId": "5241c294-43fd-4ad9-d17f-2c3cc7b68991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = StackedModel(solver_depth=5).cuda()\n",
        "train_loader = get_loader(root=\"/content/\", batch_size=3, mono=False, train=True, cap_train=5120)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 9), (9, 9)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftKIcRbg7BsZ",
        "colab_type": "code",
        "outputId": "1ade8dd5-b9b1-4be0-f09b-2a5fc367a01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "train(model, criterion, optimizer, train_loader, valid_loader, num_epochs, 1, mono=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training] Epoch: 0. Loss: None/6.698751449584961. Total Accuracy: None/0.0. Inner Accuracy: 0.15966386554621848/None:   2%|▏         | 78/5121 [00:04<04:39, 18.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-50b4b959e2e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-3e64461f0f4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, num_epochs, valid_frequency, save_interval, mono)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od6crIU6zAWk",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter Experiments\n",
        "* Things to test:\n",
        "  * Total parameters;\n",
        "  * depth of the network;\n",
        "  * increase in filter banks; \n",
        "  * One-hot output vs. continuous.\n",
        "  * Use sudoku range\n",
        "  * ConvTranspose upsampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an4PyxJ4mJuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tests = {\n",
        "    # \"mono_sd_11_linear_sudoku_range\": { \"mono\": True, \"sd\": 11, \"convtranspose\": False, \"sudoku_range\": True },\n",
        "    # \"mono_sd_11_convtran_sudoku_range\": { \"mono\": True, \"sd\": 11, \"convtranspose\": True, \"sudoku_range\": True },\n",
        "    # \"mono_sd_11_convtran\": { \"mono\": True, \"sd\": 11, \"convtranspose\": True, \"sudoku_range\": False },\n",
        "    # \"mono_sd_22_convtran\": { \"mono\": True, \"sd\": 22, \"convtranspose\": True, \"sudoku_range\": False },\n",
        "    # \"stacked_sd_11_convtran\": { \"mono\": False, \"sd\": 11, \"convtranspose\": True },\n",
        "    # \"stacked_sd_22_convtran\": { \"mono\": False, \"sd\": 22, \"convtranspose\": True },\n",
        "    # \"stacked_sd_18_convtran\": { \"mono\": False, \"sd\": 18, \"convtranspose\": True }\n",
        "    # \"stacked_sd_27_gr_3_26_convtran\": { \"mono\": False, \"sd\": 27, \"convtranspose\": True, \"growth_rate\": (3, 26) },\n",
        "    # \"stacked_sd_81_gr_3_80_convtran\": { \"mono\": False, \"sd\": 81, \"convtranspose\": True, \"growth_rate\": (3, 80) },\n",
        "    \"stacked_sd_11_gr_3_3_convtran\": { \"mono\": False, \"sd\": 15, \"convtranspose\": True, \"growth_rate\": (3, 3) },\n",
        "\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odye7eKF6h-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import path\n",
        "\n",
        "def save_test(key, **kargs):\n",
        "  f = \"/content/gdrive/My Drive/data/models/hyper_experiment.pickle\"\n",
        "  if path.exists(f):\n",
        "    existing = torch.load(f)\n",
        "  else:\n",
        "    existing = {}\n",
        "  existing[key] = kargs\n",
        "  torch.save(existing, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWD30Vmny_u3",
        "colab_type": "code",
        "outputId": "84060b69-d1bb-42bc-b091-32f93b065568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "epochs = 3\n",
        "cap_train = 1000000\n",
        "batch_size = 256\n",
        "\n",
        "for test in tests.keys():\n",
        "  params = tests[test]\n",
        "  mono = params[\"mono\"]\n",
        "  sd = params[\"sd\"]\n",
        "  convtranspose = params[\"convtranspose\"]\n",
        "  sudoku_range = params.get(\"sudoku_range\")\n",
        "  growth_rate = params.get(\"growth_rate\")\n",
        "  save_loc = f\"/content/gdrive/My Drive/data/models/HyperExp/{test}.mod\"\n",
        "\n",
        "\n",
        "  if mono:\n",
        "    model = MonoModel(solver_depth=sd, convtranspose=convtranspose, use_to_sudoku_range=sudoku_range, growth_rate=growth_rate).cuda()\n",
        "    criterion = nn.MSELoss()\n",
        "  else:\n",
        "    model = StackedModel(solver_depth=sd, convtranspose=convtranspose, growth_rate=growth_rate).cuda()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  print(f\"\\nTesting model {test} with {count_params(model)} parameters.\\n\")\n",
        "  train_loader = get_loader(root=\"/content/\", batch_size=batch_size, mono=mono, train=True, cap_train=cap_train)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  valid_loader = []\n",
        "\n",
        "  \n",
        "  model, training_losses, game_accuracies, cell_accuracies = train(model,\n",
        "                                                                   criterion,\n",
        "                                                                   optimizer,\n",
        "                                                                   train_loader=train_loader,\n",
        "                                                                   valid_loader=valid_loader,\n",
        "                                                                   num_epochs=epochs,\n",
        "                                                                   valid_frequency=1,\n",
        "                                                                   save_interval=1000,\n",
        "                                                                   mono=mono,\n",
        "                                                                   save_loc=save_loc)\n",
        "  num_params = count_params(model)\n",
        "  save_test(test, model=model.state_dict(), training_losses=training_losses, game_accuracies=game_accuracies, cell_accuracies=cell_accuracies, num_params=num_params)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 27), (27, 27), (27, 27), (27, 81), (81, 81), (81, 81), (81, 243), (243, 243), (243, 243), (243, 729), (729, 729), (729, 729)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-39d4d14b2c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvtranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrowth_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrowth_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.90 GiB total capacity; 14.54 GiB already allocated; 7.69 MiB free; 15.19 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phRyY5aYQkaw",
        "colab_type": "code",
        "outputId": "353fbdf7-a367-4cdc-9607-44177f541c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "count_params(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1640034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI7IQOZ1Jtkp",
        "colab_type": "text"
      },
      "source": [
        "# Test Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CqXI9IGJvdh",
        "colab_type": "code",
        "outputId": "e48ef8c1-016f-41a2-e57e-7ed7abc6258d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "model = StackedModel(solver_depth=15, convtranspose=True, growth_rate=(3, 4)).cuda()\n",
        "test = \"stacked_sd_15_gr_3_4_convtran\"\n",
        "state = torch.load(f\"/content/gdrive/My Drive/data/models/HyperExp/{test}.mod\")\n",
        "model.load_state_dict(state['model'])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 9), (9, 27), (27, 27), (27, 27), (27, 27), (27, 81), (81, 81), (81, 81), (81, 81), (81, 243), (243, 243), (243, 243)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR9BYitiLdOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dl = get_loader('/content/', train=False, mono=False, batch_size=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-FaGKAQLy2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from display import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpHWyBoaL1f1",
        "colab_type": "code",
        "outputId": "315ac68f-d0a0-44ae-df19-4879b1262dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "tot = torch.zeros((9,9))\n",
        "num_solved = 0\n",
        "total_puzzles = 0\n",
        "loop = tqdm(total=len(dl), position=0)\n",
        "model = model.eval()\n",
        "with torch.no_grad():\n",
        "  for i, (puzzles, solutions) in zip(range(1009000), dl):\n",
        "    # print(f\"puzzles: {puzzles.size()}, Solutions: {solutions.size()}\")\n",
        "    puzzles, solutions = puzzles.float().cuda(), solutions.long().reshape(-1, 9,9)\n",
        "    attempts = stacked_to_mono(model(puzzles)).reshape(-1, 9,9).cpu()\n",
        "    # print(f\"Attempts: {attempts.size()}, Solutions: {solutions.size()}\")\n",
        "    for attempt, solution in zip(attempts, solutions):\n",
        "      total_puzzles += 1\n",
        "      differences = attempt.eq(solution + 1).cpu().long()\n",
        "      if differences.sum().item() == 81:\n",
        "        # print(f\"Solved puzzle: \\n{attempt}\\n{solution}\\n\")\n",
        "        num_solved += 1\n",
        "      # else:\n",
        "        # print(f\"Differend by {81 - differences.sum().item()}\")\n",
        "      # print(differences)\n",
        "      tot += differences * -1 + 1\n",
        "    loop.update(1)\n",
        "    # print(\"----- Attempt -----\")\n",
        "    # print_tensor_puzzle(attempt.reshape(9,9,9))\n",
        "    # print(\"----- Solution -----\")\n",
        "    # print(solution)\n",
        "    # print(f\"Cell Accuracy: {cell_accuracy(attempt, solution.cuda(), puzzle)}\\nGAme Accuracy: {solved_accuracy(attempt, solution.cuda(), puzzle)}\")\n",
        "print(f\"\\nSolved {num_solved} / {total_puzzles}\")\n",
        "print(tot)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3907/3907 [41:27<00:00,  2.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Solved 816715 / 1000000\n",
            "tensor([[3909., 3607., 4062., 3962., 3556., 3952., 3843., 3616., 4013.],\n",
            "        [3555., 3335., 3623., 3768., 3364., 3749., 3567., 3145., 3519.],\n",
            "        [3946., 3620., 3952., 3961., 3672., 3948., 4006., 3656., 3949.],\n",
            "        [4077., 3836., 4099., 3935., 3816., 3998., 3882., 3577., 4030.],\n",
            "        [3580., 3335., 3712., 3770., 3161., 3815., 3633., 3343., 3607.],\n",
            "        [3970., 3650., 3957., 3786., 3698., 3999., 3915., 3650., 3973.],\n",
            "        [4098., 3720., 4179., 3904., 3519., 3850., 3902., 3562., 3876.],\n",
            "        [3614., 3322., 3715., 3762., 3336., 3656., 3597., 3086., 3568.],\n",
            "        [3814., 3536., 4007., 3878., 3474., 3825., 3971., 3496., 3934.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsrJjWVoV-M8",
        "colab_type": "code",
        "outputId": "9f3515db-b3e4-41da-ae51-162d486fd948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "\n",
        "# cmap = sn.cm.rocket_r\n",
        "df_cm = pd.DataFrame(tot.view(9,9).numpy(), range(9), range(9))\n",
        "sn.heatmap(df_cm, cmap=\"Blues\")\n",
        "plt.title(f\"Cell Level Failure Matrix\\n{test}\\n\")\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWYAAAEmCAYAAABRfjp6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVnBODGbmRWME7OZWcE4MZuZFcz/B5zLTCQxxW6oAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NWd9hp_PGwa",
        "colab_type": "code",
        "outputId": "7c236518-22b8-4400-e2ff-4c64b19048ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ones = torch.ones((3, 3))\n",
        "mixed = torch.zeros((3,3))\n",
        "mixed[:,1] = 1\n",
        "ones.eq(mixed) * -1 + 1\n",
        "ones.eq(mixed).sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqpVKzym5yOc",
        "colab_type": "text"
      },
      "source": [
        "# TEST ACCURACY METRIC METHODS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz9yY8QE2g3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = torch.Tensor([[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "k = torch.Tensor([[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "l = torch.Tensor([[[2,2,2],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "\n",
        "z = torch.zeros((3,3,3))\n",
        "f = z.clone()\n",
        "f[:,:,0] = k[:,:,0]\n",
        "g = z.clone()\n",
        "g[:,:,0] = l[:,:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dBEcKsHdzK0D",
        "colab": {}
      },
      "source": [
        "s = torch.load(\"/content/gdrive/My Drive/data/models/MonoModel.mod\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d0bLtoj3zJGE",
        "colab": {}
      },
      "source": [
        "s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87tkJJpvJxd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s.keys()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJPKHXaQJzbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4_LhBgUJ7-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(s[\"model\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_vlhBSszTAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = get_loader(root=\"/content/\", batch_size=2, mono=True, train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am43RsYozZKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPss7Gt6zbTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n4JyYu0zb_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x, \"\\n\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqcrr41fzd-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(puzzle_exactifier(model(x.float().cuda())), \"\\n\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koaxWgD5zriX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz8EPwfR155A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWCX7vnu16-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MonoModel(solver_depth=21).cuda()\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTwLVmAWy0n5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = get_loader(\"/content/\", mono=False, batch_size=1, cap_train=10)\n",
        "dm = get_loader(\"/content/\", mono=True, batch_size=1, cap_train=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA6BZxUizyzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs, ys = next(iter(ds))\n",
        "xm, ym = next(iter(dm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osFKZIGVz6Df",
        "colab_type": "code",
        "outputId": "984cff15-0486-436d-d237-5fc1de04b0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "y = y + 1\n",
        "x,y = x.float().cuda(), y.float().cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2914cc4f3a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKLxg6A8xWa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = [dm.dataset.data.iloc[i].puzzle for i in range(10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZlNgvYd_c0z",
        "colab_type": "code",
        "outputId": "ee586d3f-c4a7-4152-bebf-511e0a8e3804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['070000043040009610800634900094052000358460020000800530080070091902100005007040802',\n",
              " '301086504046521070500000001400800002080347900009050038004090200008734090007208103',\n",
              " '048301560360008090910670003020000935509010200670020010004002107090100008150834029',\n",
              " '008317000004205109000040070327160904901450000045700800030001060872604000416070080',\n",
              " '040890630000136820800740519000467052450020700267010000520003400010280970004050063',\n",
              " '561092730020780090900005046600000427010070003073000819035900670700103080000000050',\n",
              " '310450900072986143906010508639178020150090806004003700005731009701829350000645010',\n",
              " '800134902041096080005070010008605000406310009023040860500709000010080040000401006',\n",
              " '165293004000001632023060090009175000500900018002030049098000006000000950000429381',\n",
              " '000003610000015007000008090086000700030800100500120309005060904060900530403701008']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78FtxyGOxk2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp = torch.Tensor([dm.dataset.to_mono_grid(i) for i in p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HARmy12KyKe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp = torch.Tensor([dm.dataset.to_stacked_grid(i) for i in p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwM6ZVXAzeKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp = torch.Tensor(sp)\n",
        "sp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEl4imJizf1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp.argmax(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OFy4J6Rzosa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "((sp.argmax(dim=0)) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vor7tw5RzqCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuqOPx4dz2g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYuTIZvQz7LY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am = sp.argmax(dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZrtGe9C268R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am_mask = torch.all(sp == 0, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRmayoz12_rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9W-sMyQ3A9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.where(am_mask, torch.zeros(am_mask.size()), am.float() + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpWMzjpJ3J_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "827VFlD23L9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model_util import stacked_to_mono"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihdZ3NmC4Alk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacked_to_mono(sp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_I097__4CU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbN_ZOGG4CwZ",
        "colab_type": "code",
        "outputId": "23f3fb64-8fdb-4c45-8567-2dcfbd4acaeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sp[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dut2Bn7n_m-n",
        "colab_type": "code",
        "outputId": "432c0859-429e-4848-9c34-372b30f8e07b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "mp[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 7., 0., 0., 0., 0., 0., 4., 3.],\n",
              "         [0., 4., 0., 0., 0., 9., 6., 1., 0.],\n",
              "         [8., 0., 0., 6., 3., 4., 9., 0., 0.],\n",
              "         [0., 9., 4., 0., 5., 2., 0., 0., 0.],\n",
              "         [3., 5., 8., 4., 6., 0., 0., 2., 0.],\n",
              "         [0., 0., 0., 8., 0., 0., 5., 3., 0.],\n",
              "         [0., 8., 0., 0., 7., 0., 0., 9., 1.],\n",
              "         [9., 0., 2., 1., 0., 0., 0., 0., 5.],\n",
              "         [0., 0., 7., 0., 4., 0., 8., 0., 2.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DrDF_5A_oZ-",
        "colab_type": "code",
        "outputId": "d6eb75be-91e2-4a14-accc-c5df7b9073bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "stacked_to_mono(sp)[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 7., 0., 0., 0., 0., 0., 4., 3.],\n",
              "        [0., 4., 0., 0., 0., 9., 6., 1., 0.],\n",
              "        [8., 0., 0., 6., 3., 4., 9., 0., 0.],\n",
              "        [0., 9., 4., 0., 5., 2., 0., 0., 0.],\n",
              "        [3., 5., 8., 4., 6., 0., 0., 2., 0.],\n",
              "        [0., 0., 0., 8., 0., 0., 5., 3., 0.],\n",
              "        [0., 8., 0., 0., 7., 0., 0., 9., 1.],\n",
              "        [9., 0., 2., 1., 0., 0., 0., 0., 5.],\n",
              "        [0., 0., 7., 0., 4., 0., 8., 0., 2.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m5_vXWQ_9DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stacked_to_mono_old(puzzles):\n",
        "    zeros_mask = torch.all(puzzles == 0, dim=1).cuda()\n",
        "    maxes = puzzles.argmax(dim=1).cuda()\n",
        "    return torch.where(zeros_mask, torch.zeros(zeros_mask.size()).cuda(), maxes.float().cuda() + 1).cuda().unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-evJNOU__uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translated = stacked_to_mono(sp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPQVYLktsRic",
        "colab_type": "code",
        "outputId": "aac25a83-6ab3-4ae6-ed2f-a7ef14421f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "translated.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5qeJBNVsTDZ",
        "colab_type": "code",
        "outputId": "7fede6f4-175d-41bf-ca1d-a3e4123af278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNG0Ng14sUrI",
        "colab_type": "code",
        "outputId": "be4623d4-b43f-47ef-b431-8c3b0cc8b25d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "translated.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uQ-HEwxseOC",
        "colab_type": "code",
        "outputId": "ddf33d63-6e22-4762-f485-a7f36ba61dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.all(mp == translated)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Expy3u1Uska5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}