{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "TestLoader.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW6VWCHjm-g6",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tMQ3_yDj_md",
        "colab_type": "code",
        "outputId": "c20c9c5c-64c4-4da1-e184-b8050ac2de10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp /content/gdrive/My\\ Drive/data/*.zip .\n",
        "!unzip /content/sudoku.zip\n",
        "!mkdir /content/test\n",
        "!unzip /content/sudoku_test.zip -d /content/test\n",
        "!mv /content/test/sudoku.csv /content/sudoku_test.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Archive:  /content/sudoku.zip\n",
            "  inflating: sudoku.csv              \n",
            "Archive:  /content/sudoku_test.zip\n",
            "  inflating: /content/test/sudoku.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cghus0djA4Q",
        "colab_type": "code",
        "outputId": "addb36fd-757f-46b0-e68c-f02f1d99ec6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!rm -rf drl-sudoku\n",
        "!git clone https://github.com/cloughurd/drl-sudoku.git\n",
        "!mv drl-sudoku/data/* ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'drl-sudoku'...\n",
            "remote: Enumerating objects: 202, done.\u001b[K\n",
            "remote: Counting objects: 100% (202/202), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 202 (delta 126), reused 72 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (202/202), 322.66 KiB | 1.23 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaIypeXinqFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import math\n",
        "import contextlib\n",
        "from typing import List, Tuple\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from model_util import stacked_to_mono, count_params\n",
        "\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFMABO1nnB7f",
        "colab_type": "text"
      },
      "source": [
        "# Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxiPBreTi7Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataloader import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqQdT8QAnZXa",
        "colab_type": "text"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1WF_WlwqVlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJM42t58rc79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToSudokuRange(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ToSudokuRange, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.net = lambda x: (9 * self.sigmoid(x)) + 0.5\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MecL5K3ielK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SolverLayer(nn.Module):\n",
        "  def __init__(self, in_filters:int, hidden_filters:int, out_filters:int, convtranspose:bool=True):\n",
        "    super(SolverLayer, self).__init__()\n",
        "\n",
        "    if in_filters != out_filters:\n",
        "      self.skip = nn.Conv2d(in_filters, out_filters, kernel_size=1)\n",
        "    else:\n",
        "      self.skip = nn.Identity()\n",
        "\n",
        "    self.initial_normalization = nn.InstanceNorm2d(in_filters) # Normalize every individual game within its filters. Not positive this is a good idea... maybe use the 3d version?\n",
        "\n",
        "    self.HorizontalDependencies = self._get_dependency_module(in_filters, hidden_filters, (9,1), convtranspose=convtranspose)\n",
        "    self.VerticalDependencies = self._get_dependency_module(in_filters, hidden_filters, (1,9), convtranspose=convtranspose)\n",
        "    self.QuadrantDependencies = self._get_dependency_module(in_filters, hidden_filters, (3, 3), stride=3, convtranspose=convtranspose)\n",
        "\n",
        "    num_hidden = hidden_filters * 3\n",
        "    \n",
        "    self.Reduce = nn.Sequential(\n",
        "        nn.Conv2d(num_hidden, num_hidden, kernel_size=(3, 3), padding=1),\n",
        "        nn.Conv2d(num_hidden, out_filters, kernel_size=(1, 1)), # Look at each cell only, without neighbors; neighbors have already been considered.\n",
        "        nn.LeakyReLU()\n",
        "    )\n",
        "\n",
        "    self.Final = nn.LeakyReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    skip = self.skip(x)\n",
        "    x = self.initial_normalization(x)\n",
        "    horizontal_result = self.HorizontalDependencies(x)\n",
        "    vertical_result = self.VerticalDependencies(x)\n",
        "    quadrant_result = self.QuadrantDependencies(x)\n",
        "\n",
        "    combined = torch.cat((horizontal_result, vertical_result, quadrant_result), dim=1)\n",
        "\n",
        "    reduced = self.Reduce(combined)\n",
        "\n",
        "    residualized = reduced + skip\n",
        "    return self.Final(residualized)\n",
        "\n",
        "  def _get_dependency_module(self, in_filters, hidden_filters, kernel_size, stride=None, convtranspose=False):\n",
        "    if stride is None:\n",
        "      stride = 1\n",
        "      \n",
        "    if convtranspose:\n",
        "        return nn.Sequential(\n",
        "          nn.Conv2d(in_filters, hidden_filters*9, kernel_size=kernel_size, stride=stride),\n",
        "          nn.BatchNorm2d(hidden_filters*9),\n",
        "          nn.LeakyReLU(),\n",
        "          nn.ConvTranspose2d(hidden_filters*9, hidden_filters, kernel_size=kernel_size, stride=stride),\n",
        "          nn.BatchNorm2d(hidden_filters),\n",
        "          nn.Dropout(),\n",
        "          nn.LeakyReLU()\n",
        "      )\n",
        "    else:\n",
        "      return nn.Sequential(\n",
        "          nn.Conv2d(in_filters, hidden_filters, kernel_size=kernel_size, stride=stride),\n",
        "          nn.BatchNorm2d(hidden_filters),\n",
        "          nn.LeakyReLU(),\n",
        "          Reshape((-1, hidden_filters, 9)),\n",
        "          # Make into a full board shape that can be recombined... Maybe?\n",
        "          nn.Linear(9, 81), \n",
        "          nn.BatchNorm1d(hidden_filters),\n",
        "          nn.Dropout(),\n",
        "          Reshape((-1, hidden_filters, 9, 9)),\n",
        "          nn.LeakyReLU()\n",
        "      )\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG34hwOxnY74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MonoModel(nn.Module):\n",
        "  def __init__(self, solver_depth:int, convtranspose:bool=True, use_to_sudoku_range=True, growth_rate:Tuple[int]=(3,9)):\n",
        "    super(MonoModel, self).__init__()\n",
        "    if type(growth_rate) == int:\n",
        "      growth_base = 3\n",
        "      growth_frequency = growth_rate\n",
        "    else:\n",
        "      growth_base, growth_frequency = growth_rate\n",
        "    layer_numbers = [(growth_base**(i // growth_frequency + 2), growth_base**( (i+1) // growth_frequency + 2)) for i in range(solver_depth - 2)]\n",
        "    print(layer_numbers)\n",
        "    reducer_layer = layer_numbers[-1][1]\n",
        "    self.net = nn.Sequential(\n",
        "        SolverLayer(1, 9, 9, convtranspose=convtranspose),\n",
        "        *[ SolverLayer(i, i, o, convtranspose=convtranspose) for i, o in layer_numbers],\n",
        "        SolverLayer(reducer_layer, reducer_layer, 1, convtranspose=convtranspose),\n",
        "        Reshape((-1, 1, 9, 9)),\n",
        "        ToSudokuRange() if use_to_sudoku_range else nn.Identity()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3QgEnxzop79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StackedModel(nn.Module):\n",
        "  def __init__(self, solver_depth:int, convtranspose:bool=True, growth_rate:Tuple[int]=(3,9)):\n",
        "    super(StackedModel, self).__init__()\n",
        "    if type(growth_rate) == int:\n",
        "      growth_base = 3\n",
        "      growth_frequency = growth_rate\n",
        "    else:\n",
        "      growth_base, growth_frequency = growth_rate\n",
        "    layer_numbers = [(growth_base**(i // growth_frequency + 2), growth_base**( (i+1) // growth_frequency + 2)) for i in range(solver_depth - 1)]\n",
        "    print(layer_numbers)\n",
        "    reducer_layer = layer_numbers[-1][1]\n",
        "    self.net = nn.Sequential(\n",
        "        *[ SolverLayer(i, i, o, convtranspose=convtranspose) for i, o in layer_numbers],\n",
        "        SolverLayer(reducer_layer, reducer_layer, 9, convtranspose=convtranspose),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_A2vsv3q76T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def puzzle_exactifier(p):\n",
        "  return torch.round(p)\n",
        "\n",
        "\n",
        "\n",
        "def puzzle_masker(attempts, starting_puzzles):\n",
        "  assert attempts.size() == starting_puzzles.size()\n",
        "  num_filled_in_solution = torch.sum(starting_puzzles != 0).item()\n",
        "  attempts = torch.where(starting_puzzles == 0, attempts, starting_puzzles)\n",
        "  return (attempts, starting_puzzles, num_filled_in_solution)\n",
        "\n",
        "def solved_accuracy(attempts, solutions, starting_puzzles):\n",
        "  # print(f\"Puzzle Acc Before if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  if len(attempts.size()) == 4 and attempts.size(1) == 9:\n",
        "    attempts = stacked_to_mono(attempts).squeeze(1)\n",
        "    starting_puzzles = stacked_to_mono(starting_puzzles).squeeze(1)\n",
        "    solutions = solutions + 1\n",
        "  # print(f\"After if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  assert attempts.size() == solutions.size()\n",
        "  masked_puzzle, _, _ = puzzle_masker(attempts, starting_puzzles)\n",
        "  # print(masked_puzzle, solutions, starting_puzzles)\n",
        "  num_puzzles = attempts.size(0)\n",
        "  num_correct = (masked_puzzle.eq(solutions).sum(1).sum(1) == 9).sum().item()\n",
        "  # if num_correct > 0:\n",
        "    # print(\"\\n-Masked - \\n\", masked_puzzle, \"\\n- Solutions -\\n\", solutions)\n",
        "  return num_correct / num_puzzles\n",
        "\n",
        "def cell_accuracy(attempts, solutions, starting_puzzles):\n",
        "  # print(f\"Cell Acc Before if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  if len(attempts.size()) == 4 and attempts.size(1) == 9:\n",
        "    attempts = stacked_to_mono(attempts)\n",
        "    starting_puzzles = stacked_to_mono(starting_puzzles)\n",
        "    solutions = solutions + 1\n",
        "  # print(f\"After if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  assert attempts.size() == solutions.size()\n",
        "  masked_puzzle, _, num_filled = puzzle_masker(attempts, starting_puzzles)\n",
        "  print(\"\\nAttempts:\\n\", attempts, \"\\nMasked\\n\", masked_puzzle, \"\\nInitial\\n\", starting_puzzles, \"\\nSolution\\n\", solutions)\n",
        "  num_cells = attempts.numel()\n",
        "  print(f\"Comparison: \\n{masked_puzzle.eq(solutions)}\")\n",
        "  num_correct = masked_puzzle.eq(solutions).sum().item()\n",
        "  num_guessed_correctly = num_correct - num_filled\n",
        "  num_to_guess = num_cells - num_filled\n",
        "  # print(f\"--- {num_cells} - {num_correct} - {num_cells} - {num_filled} ---\")\n",
        "  return num_guessed_correctly / num_to_guess\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiPAmV3Eq5vi",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu-uveXztc8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_out(save_loc:str, model:MonoModel, **kargs):\n",
        "  if save_loc is None:\n",
        "    print(\"Skipping save, no save_loc provided.\")\n",
        "    return\n",
        "  else:\n",
        "    print(f\"Saving to {save_loc}\")\n",
        "  state = {\n",
        "      \"model\": model.state_dict()\n",
        "  }\n",
        "\n",
        "  for k, v in kargs.items():\n",
        "    state[k]=v\n",
        "  \n",
        "  torch.save(state, save_loc)\n",
        "\n",
        "def train(model:MonoModel,\n",
        "          criterion:torch.nn.modules.loss._Loss,\n",
        "          optimizer:torch.optim.Optimizer,\n",
        "          train_loader:DataLoader,\n",
        "          valid_loader:DataLoader,\n",
        "          num_epochs:int,\n",
        "          valid_frequency:int=5,\n",
        "          save_interval:int=1000,\n",
        "          mono=True,\n",
        "          save_loc:str=None):\n",
        "  loop = tqdm(total=num_epochs * len(train_loader) + (num_epochs // valid_frequency) * len(valid_loader), position=0)\n",
        "\n",
        "  # The loss of the last training and validation iteration, respectively.  \n",
        "  train_loss = None\n",
        "  valid_loss = None\n",
        "\n",
        "  # The puzzle accuracy of the last training and validation itersions. ( # puzzles right / # puzzles total )\n",
        "  train_accuracy = None\n",
        "  valid_accuracy = None\n",
        "\n",
        "  # The cell accuracy of the last training and validation iterations ( # filled cells right / # num fillable cells )\n",
        "  train_inner_acc = None\n",
        "  valid_inner_acc = None\n",
        "\n",
        "  tot_training_losses = []\n",
        "  tot_training_accuracies = []\n",
        "  tot_training_cell_accuracies = []\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "\n",
        "    training_losses = []\n",
        "    training_accuracies = []\n",
        "    training_cell_accuracies = []\n",
        "\n",
        "    loop.set_description(f\"[Training] Epoch: {e}. Loss: {valid_loss}/{train_loss}. Total Accuracy: {train_accuracy}/{valid_accuracy}. Inner Accuracy: {train_inner_acc}/{valid_inner_acc}\")\n",
        "\n",
        "    for i, (puzzle, solution) in enumerate(train_loader):\n",
        "      if mono:\n",
        "        puzzle, solution = puzzle.float().cuda(async=False), (solution.float() + 1).cuda(async=False).unsqueeze(1)\n",
        "      else:\n",
        "        puzzle, solution = puzzle.float().cuda(async=False), solution.long().cuda(async=False)\n",
        "\n",
        "      # print(f\"\\nPuzzle: {puzzle.size()}; solution: {solution.size()}\")\n",
        "      # initial_puzzle = puzzle.clone()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      attempt = model(puzzle)\n",
        "\n",
        "      if mono:\n",
        "        loss = criterion(attempt, solution)\n",
        "      else:\n",
        "        solution_in = solution.view(-1, 81)\n",
        "        attempt_in = attempt.view(-1, 9, 81)\n",
        "        loss = criterion(attempt_in, solution_in)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss = loss.item()\n",
        "      training_losses.append(train_loss)\n",
        "\n",
        "      # Compute accuracies\n",
        "      exactified = puzzle_exactifier(attempt)\n",
        "\n",
        "      solve_accuracy = solved_accuracy(exactified, solution, puzzle)\n",
        "      c_acc = cell_accuracy(exactified, solution, puzzle)\n",
        "\n",
        "      train_accuracy = solve_accuracy\n",
        "      training_accuracies.append(train_accuracy)\n",
        "\n",
        "      train_inner_acc = c_acc\n",
        "      training_cell_accuracies.append(train_inner_acc)\n",
        "\n",
        "      loop.set_description(f\"[Training] Epoch: {e}. Loss: {valid_loss}/{train_loss}. Total Accuracy: {valid_accuracy}/{train_accuracy}. Inner Accuracy: {train_inner_acc}/{valid_inner_acc}\")\n",
        "      loop.update()\n",
        "\n",
        "      if i % save_interval == 0:\n",
        "        tmp_losses = tot_training_losses + [training_losses]\n",
        "        tmp_game_accs = tot_training_accuracies + [training_accuracies]\n",
        "        tmp_cell_accs = tot_training_cell_accuracies + [training_cell_accuracies]\n",
        "        save_out(save_loc, model, train_loss=tmp_losses, train_game_accs=tmp_game_accs, train_cell_accs=tmp_cell_accs, epoch=e, iteration=i)\n",
        "    tot_training_losses.append(training_losses)\n",
        "    tot_training_accuracies.append(training_accuracies)\n",
        "    tot_training_cell_accuracies.append(training_cell_accuracies)\n",
        "    save_out(save_loc, model, train_loss=tot_training_losses, train_game_accs=tot_training_accuracies, train_cell_accs=tot_training_cell_accuracies, epoch=e, iteration=-1)\n",
        "  return model, tot_training_losses, tot_training_accuracies, tot_training_cell_accuracies\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRJwXojO6QGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MonoModel(solver_depth=5).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "train_loader = get_loader(root=\"/content/\", batch_size=3, mono=True, train=True, cap_train=5120)\n",
        "valid_loader = []\n",
        "num_epochs = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlGR35vHqScP",
        "colab_type": "code",
        "outputId": "5241c294-43fd-4ad9-d17f-2c3cc7b68991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = StackedModel(solver_depth=5).cuda()\n",
        "train_loader = get_loader(root=\"/content/\", batch_size=3, mono=False, train=True, cap_train=5120)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 9), (9, 9)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftKIcRbg7BsZ",
        "colab_type": "code",
        "outputId": "1ade8dd5-b9b1-4be0-f09b-2a5fc367a01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "train(model, criterion, optimizer, train_loader, valid_loader, num_epochs, 1, mono=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training] Epoch: 0. Loss: None/6.698751449584961. Total Accuracy: None/0.0. Inner Accuracy: 0.15966386554621848/None:   2%|▏         | 78/5121 [00:04<04:39, 18.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-50b4b959e2e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-3e64461f0f4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, num_epochs, valid_frequency, save_interval, mono)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od6crIU6zAWk",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter Experiments\n",
        "* Things to test:\n",
        "  * Total parameters;\n",
        "  * depth of the network;\n",
        "  * increase in filter banks; \n",
        "  * One-hot output vs. continuous.\n",
        "  * Use sudoku range\n",
        "  * ConvTranspose upsampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an4PyxJ4mJuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tests = {\n",
        "    # \"mono_sd_11_linear_sudoku_range\": { \"mono\": True, \"sd\": 11, \"convtranspose\": False, \"sudoku_range\": True },\n",
        "    # \"mono_sd_11_convtran_sudoku_range\": { \"mono\": True, \"sd\": 11, \"convtranspose\": True, \"sudoku_range\": True },\n",
        "    # \"mono_sd_11_convtran\": { \"mono\": True, \"sd\": 11, \"convtranspose\": True, \"sudoku_range\": False },\n",
        "    # \"mono_sd_22_convtran\": { \"mono\": True, \"sd\": 22, \"convtranspose\": True, \"sudoku_range\": False },\n",
        "    # \"stacked_sd_11_convtran\": { \"mono\": False, \"sd\": 11, \"convtranspose\": True },\n",
        "    # \"stacked_sd_22_convtran\": { \"mono\": False, \"sd\": 22, \"convtranspose\": True },\n",
        "    # \"stacked_sd_18_convtran\": { \"mono\": False, \"sd\": 18, \"convtranspose\": True }\n",
        "    # \"stacked_sd_27_gr_3_26_convtran\": { \"mono\": False, \"sd\": 27, \"convtranspose\": True, \"growth_rate\": (3, 26) },\n",
        "    # \"stacked_sd_81_gr_3_80_convtran\": { \"mono\": False, \"sd\": 81, \"convtranspose\": True, \"growth_rate\": (3, 80) },\n",
        "    \"stacked_sd_11_gr_3_3_convtran\": { \"mono\": False, \"sd\": 15, \"convtranspose\": True, \"growth_rate\": (3, 3) },\n",
        "\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odye7eKF6h-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import path\n",
        "\n",
        "def save_test(key, **kargs):\n",
        "  f = \"/content/gdrive/My Drive/data/models/hyper_experiment.pickle\"\n",
        "  if path.exists(f):\n",
        "    existing = torch.load(f)\n",
        "  else:\n",
        "    existing = {}\n",
        "  existing[key] = kargs\n",
        "  torch.save(existing, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWD30Vmny_u3",
        "colab_type": "code",
        "outputId": "84060b69-d1bb-42bc-b091-32f93b065568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "epochs = 3\n",
        "cap_train = 1000000\n",
        "batch_size = 256\n",
        "\n",
        "for test in tests.keys():\n",
        "  params = tests[test]\n",
        "  mono = params[\"mono\"]\n",
        "  sd = params[\"sd\"]\n",
        "  convtranspose = params[\"convtranspose\"]\n",
        "  sudoku_range = params.get(\"sudoku_range\")\n",
        "  growth_rate = params.get(\"growth_rate\")\n",
        "  save_loc = f\"/content/gdrive/My Drive/data/models/HyperExp/{test}.mod\"\n",
        "\n",
        "\n",
        "  if mono:\n",
        "    model = MonoModel(solver_depth=sd, convtranspose=convtranspose, use_to_sudoku_range=sudoku_range, growth_rate=growth_rate).cuda()\n",
        "    criterion = nn.MSELoss()\n",
        "  else:\n",
        "    model = StackedModel(solver_depth=sd, convtranspose=convtranspose, growth_rate=growth_rate).cuda()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  print(f\"\\nTesting model {test} with {count_params(model)} parameters.\\n\")\n",
        "  train_loader = get_loader(root=\"/content/\", batch_size=batch_size, mono=mono, train=True, cap_train=cap_train)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  valid_loader = []\n",
        "\n",
        "  \n",
        "  model, training_losses, game_accuracies, cell_accuracies = train(model,\n",
        "                                                                   criterion,\n",
        "                                                                   optimizer,\n",
        "                                                                   train_loader=train_loader,\n",
        "                                                                   valid_loader=valid_loader,\n",
        "                                                                   num_epochs=epochs,\n",
        "                                                                   valid_frequency=1,\n",
        "                                                                   save_interval=1000,\n",
        "                                                                   mono=mono,\n",
        "                                                                   save_loc=save_loc)\n",
        "  num_params = count_params(model)\n",
        "  save_test(test, model=model.state_dict(), training_losses=training_losses, game_accuracies=game_accuracies, cell_accuracies=cell_accuracies, num_params=num_params)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 27), (27, 27), (27, 27), (27, 81), (81, 81), (81, 81), (81, 243), (243, 243), (243, 243), (243, 729), (729, 729), (729, 729)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-39d4d14b2c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvtranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrowth_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrowth_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.90 GiB total capacity; 14.54 GiB already allocated; 7.69 MiB free; 15.19 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phRyY5aYQkaw",
        "colab_type": "code",
        "outputId": "353fbdf7-a367-4cdc-9607-44177f541c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "count_params(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1640034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI7IQOZ1Jtkp",
        "colab_type": "text"
      },
      "source": [
        "# Test Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CqXI9IGJvdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ec330504-4b17-441c-c547-e48b39ce7de7"
      },
      "source": [
        "model = StackedModel(solver_depth=15, convtranspose=True, growth_rate=(3, 4)).cuda()\n",
        "test = \"stacked_sd_11_gr_3_4_convtran\"\n",
        "state = torch.load(f\"/content/gdrive/My Drive/data/models/HyperExp/{test}.mod\")\n",
        "model.load_state_dict(state['model'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 9), (9, 27), (27, 27), (27, 27), (27, 27), (27, 81), (81, 81), (81, 81), (81, 81), (81, 243), (243, 243), (243, 243)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR9BYitiLdOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dl = get_loader('/content/', train=False, mono=False, batch_size=256, cap_train=2560)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-FaGKAQLy2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from display import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpHWyBoaL1f1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "12795b8e-a92e-4321-ad78-5149b1285089"
      },
      "source": [
        "tot = torch.zeros((9,9))\n",
        "num_solved = 0\n",
        "total_puzzles = 0\n",
        "loop = tqdm(total=len(dl), position=0)\n",
        "model = model.eval()\n",
        "with torch.no_grad():\n",
        "  for i, (puzzles, solutions) in zip(range(1009000), dl):\n",
        "    # print(f\"puzzles: {puzzles.size()}, Solutions: {solutions.size()}\")\n",
        "    puzzles, solutions = puzzles.float().cuda(), solutions.long().reshape(-1, 9,9)\n",
        "    attempts = stacked_to_mono(model(puzzles)).reshape(-1, 9,9).cpu()\n",
        "    # print(f\"Attempts: {attempts.size()}, Solutions: {solutions.size()}\")\n",
        "    for attempt, solution in zip(attempts, solutions):\n",
        "      total_puzzles += 1\n",
        "      differences = attempt.eq(solution + 1).cpu().long()\n",
        "      if differences.sum().item() == 81:\n",
        "        # print(f\"Solved puzzle: \\n{attempt}\\n{solution}\\n\")\n",
        "        num_solved += 1\n",
        "      # else:\n",
        "        # print(f\"Differend by {81 - differences.sum().item()}\")\n",
        "      # print(differences)\n",
        "      tot += differences * -1 + 1\n",
        "    loop.update(1)\n",
        "    # print(\"----- Attempt -----\")\n",
        "    # print_tensor_puzzle(attempt.reshape(9,9,9))\n",
        "    # print(\"----- Solution -----\")\n",
        "    # print(solution)\n",
        "    # print(f\"Cell Accuracy: {cell_accuracy(attempt, solution.cuda(), puzzle)}\\nGAme Accuracy: {solved_accuracy(attempt, solution.cuda(), puzzle)}\")\n",
        "print(f\"\\nSolved {num_solved} / {total_puzzles}\")\n",
        "print(tot)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:22<00:00,  2.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Solved 808 / 2560\n",
            "tensor([[64., 99., 61., 66., 65., 66., 61., 92., 91.],\n",
            "        [51., 61., 58., 50., 46., 61., 63., 53., 51.],\n",
            "        [64., 65., 57., 62., 61., 71., 45., 49., 61.],\n",
            "        [73., 90., 77., 70., 84., 77., 57., 95., 71.],\n",
            "        [51., 66., 54., 69., 45., 72., 62., 54., 76.],\n",
            "        [58., 71., 56., 64., 35., 51., 54., 56., 66.],\n",
            "        [53., 82., 53., 53., 81., 51., 56., 83., 56.],\n",
            "        [48., 43., 57., 50., 50., 64., 38., 48., 63.],\n",
            "        [69., 72., 63., 44., 54., 55., 52., 54., 65.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsrJjWVoV-M8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "87db39d6-7511-47b8-90a5-ea579c843261"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "\n",
        "df_cm = pd.DataFrame(tot.view(9,9).numpy(), range(9), range(9))\n",
        "sn.heatmap(df_cm) # font size\n",
        "plt.show()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NWd9hp_PGwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c236518-22b8-4400-e2ff-4c64b19048ab"
      },
      "source": [
        "ones = torch.ones((3, 3))\n",
        "mixed = torch.zeros((3,3))\n",
        "mixed[:,1] = 1\n",
        "ones.eq(mixed) * -1 + 1\n",
        "ones.eq(mixed).sum()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqpVKzym5yOc",
        "colab_type": "text"
      },
      "source": [
        "# TEST ACCURACY METRIC METHODS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz9yY8QE2g3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = torch.Tensor([[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "k = torch.Tensor([[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "l = torch.Tensor([[[2,2,2],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "\n",
        "z = torch.zeros((3,3,3))\n",
        "f = z.clone()\n",
        "f[:,:,0] = k[:,:,0]\n",
        "g = z.clone()\n",
        "g[:,:,0] = l[:,:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dBEcKsHdzK0D",
        "colab": {}
      },
      "source": [
        "s = torch.load(\"/content/gdrive/My Drive/data/models/MonoModel.mod\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d0bLtoj3zJGE",
        "colab": {}
      },
      "source": [
        "s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87tkJJpvJxd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s.keys()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJPKHXaQJzbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4_LhBgUJ7-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(s[\"model\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_vlhBSszTAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = get_loader(root=\"/content/\", batch_size=2, mono=True, train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am43RsYozZKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPss7Gt6zbTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n4JyYu0zb_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x, \"\\n\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqcrr41fzd-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(puzzle_exactifier(model(x.float().cuda())), \"\\n\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koaxWgD5zriX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz8EPwfR155A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWCX7vnu16-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MonoModel(solver_depth=21).cuda()\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTwLVmAWy0n5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = get_loader(\"/content/\", mono=False, batch_size=1, cap_train=10)\n",
        "dm = get_loader(\"/content/\", mono=True, batch_size=1, cap_train=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA6BZxUizyzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs, ys = next(iter(ds))\n",
        "xm, ym = next(iter(dm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osFKZIGVz6Df",
        "colab_type": "code",
        "outputId": "984cff15-0486-436d-d237-5fc1de04b0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "y = y + 1\n",
        "x,y = x.float().cuda(), y.float().cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2914cc4f3a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKLxg6A8xWa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = [dm.dataset.data.iloc[i].puzzle for i in range(10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZlNgvYd_c0z",
        "colab_type": "code",
        "outputId": "ee586d3f-c4a7-4152-bebf-511e0a8e3804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['070000043040009610800634900094052000358460020000800530080070091902100005007040802',\n",
              " '301086504046521070500000001400800002080347900009050038004090200008734090007208103',\n",
              " '048301560360008090910670003020000935509010200670020010004002107090100008150834029',\n",
              " '008317000004205109000040070327160904901450000045700800030001060872604000416070080',\n",
              " '040890630000136820800740519000467052450020700267010000520003400010280970004050063',\n",
              " '561092730020780090900005046600000427010070003073000819035900670700103080000000050',\n",
              " '310450900072986143906010508639178020150090806004003700005731009701829350000645010',\n",
              " '800134902041096080005070010008605000406310009023040860500709000010080040000401006',\n",
              " '165293004000001632023060090009175000500900018002030049098000006000000950000429381',\n",
              " '000003610000015007000008090086000700030800100500120309005060904060900530403701008']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78FtxyGOxk2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp = torch.Tensor([dm.dataset.to_mono_grid(i) for i in p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HARmy12KyKe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp = torch.Tensor([dm.dataset.to_stacked_grid(i) for i in p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwM6ZVXAzeKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp = torch.Tensor(sp)\n",
        "sp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEl4imJizf1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp.argmax(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OFy4J6Rzosa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "((sp.argmax(dim=0)) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vor7tw5RzqCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuqOPx4dz2g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYuTIZvQz7LY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am = sp.argmax(dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZrtGe9C268R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am_mask = torch.all(sp == 0, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRmayoz12_rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9W-sMyQ3A9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.where(am_mask, torch.zeros(am_mask.size()), am.float() + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpWMzjpJ3J_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "827VFlD23L9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model_util import stacked_to_mono"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihdZ3NmC4Alk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacked_to_mono(sp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_I097__4CU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbN_ZOGG4CwZ",
        "colab_type": "code",
        "outputId": "23f3fb64-8fdb-4c45-8567-2dcfbd4acaeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sp[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dut2Bn7n_m-n",
        "colab_type": "code",
        "outputId": "432c0859-429e-4848-9c34-372b30f8e07b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "mp[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 7., 0., 0., 0., 0., 0., 4., 3.],\n",
              "         [0., 4., 0., 0., 0., 9., 6., 1., 0.],\n",
              "         [8., 0., 0., 6., 3., 4., 9., 0., 0.],\n",
              "         [0., 9., 4., 0., 5., 2., 0., 0., 0.],\n",
              "         [3., 5., 8., 4., 6., 0., 0., 2., 0.],\n",
              "         [0., 0., 0., 8., 0., 0., 5., 3., 0.],\n",
              "         [0., 8., 0., 0., 7., 0., 0., 9., 1.],\n",
              "         [9., 0., 2., 1., 0., 0., 0., 0., 5.],\n",
              "         [0., 0., 7., 0., 4., 0., 8., 0., 2.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DrDF_5A_oZ-",
        "colab_type": "code",
        "outputId": "d6eb75be-91e2-4a14-accc-c5df7b9073bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "stacked_to_mono(sp)[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 7., 0., 0., 0., 0., 0., 4., 3.],\n",
              "        [0., 4., 0., 0., 0., 9., 6., 1., 0.],\n",
              "        [8., 0., 0., 6., 3., 4., 9., 0., 0.],\n",
              "        [0., 9., 4., 0., 5., 2., 0., 0., 0.],\n",
              "        [3., 5., 8., 4., 6., 0., 0., 2., 0.],\n",
              "        [0., 0., 0., 8., 0., 0., 5., 3., 0.],\n",
              "        [0., 8., 0., 0., 7., 0., 0., 9., 1.],\n",
              "        [9., 0., 2., 1., 0., 0., 0., 0., 5.],\n",
              "        [0., 0., 7., 0., 4., 0., 8., 0., 2.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m5_vXWQ_9DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stacked_to_mono_old(puzzles):\n",
        "    zeros_mask = torch.all(puzzles == 0, dim=1).cuda()\n",
        "    maxes = puzzles.argmax(dim=1).cuda()\n",
        "    return torch.where(zeros_mask, torch.zeros(zeros_mask.size()).cuda(), maxes.float().cuda() + 1).cuda().unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-evJNOU__uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translated = stacked_to_mono(sp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPQVYLktsRic",
        "colab_type": "code",
        "outputId": "aac25a83-6ab3-4ae6-ed2f-a7ef14421f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "translated.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5qeJBNVsTDZ",
        "colab_type": "code",
        "outputId": "7fede6f4-175d-41bf-ca1d-a3e4123af278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNG0Ng14sUrI",
        "colab_type": "code",
        "outputId": "be4623d4-b43f-47ef-b431-8c3b0cc8b25d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "translated.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uQ-HEwxseOC",
        "colab_type": "code",
        "outputId": "ddf33d63-6e22-4762-f485-a7f36ba61dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.all(mp == translated)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Expy3u1Uska5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}