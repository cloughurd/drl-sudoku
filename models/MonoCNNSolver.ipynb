{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "TestLoader.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW6VWCHjm-g6",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tMQ3_yDj_md",
        "colab_type": "code",
        "outputId": "c20c9c5c-64c4-4da1-e184-b8050ac2de10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp /content/gdrive/My\\ Drive/data/*.zip .\n",
        "!unzip /content/sudoku.zip\n",
        "!mkdir /content/test\n",
        "!unzip /content/sudoku_test.zip -d /content/test\n",
        "!mv /content/test/sudoku.csv /content/sudoku_test.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Archive:  /content/sudoku.zip\n",
            "  inflating: sudoku.csv              \n",
            "Archive:  /content/sudoku_test.zip\n",
            "  inflating: /content/test/sudoku.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cghus0djA4Q",
        "colab_type": "code",
        "outputId": "addb36fd-757f-46b0-e68c-f02f1d99ec6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!rm -rf drl-sudoku\n",
        "!git clone https://github.com/cloughurd/drl-sudoku.git\n",
        "!mv drl-sudoku/data/* ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'drl-sudoku'...\n",
            "remote: Enumerating objects: 202, done.\u001b[K\n",
            "remote: Counting objects: 100% (202/202), done.\u001b[K\n",
            "remote: Compressing objects: 100% (161/161), done.\u001b[K\n",
            "remote: Total 202 (delta 126), reused 72 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (202/202), 322.66 KiB | 1.23 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaIypeXinqFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import math\n",
        "import contextlib\n",
        "from typing import List, Tuple\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from model_util import stacked_to_mono, count_params\n",
        "\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFMABO1nnB7f",
        "colab_type": "text"
      },
      "source": [
        "# Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxiPBreTi7Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataloader import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqQdT8QAnZXa",
        "colab_type": "text"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1WF_WlwqVlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJM42t58rc79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToSudokuRange(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ToSudokuRange, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.net = lambda x: (9 * self.sigmoid(x)) + 0.5\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MecL5K3ielK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SolverLayer(nn.Module):\n",
        "  def __init__(self, in_filters:int, hidden_filters:int, out_filters:int, convtranspose:bool=True):\n",
        "    super(SolverLayer, self).__init__()\n",
        "\n",
        "    if in_filters != out_filters:\n",
        "      self.skip = nn.Conv2d(in_filters, out_filters, kernel_size=1)\n",
        "    else:\n",
        "      self.skip = nn.Identity()\n",
        "\n",
        "    self.initial_normalization = nn.InstanceNorm2d(in_filters) # Normalize every individual game within its filters. Not positive this is a good idea... maybe use the 3d version?\n",
        "\n",
        "    self.HorizontalDependencies = self._get_dependency_module(in_filters, hidden_filters, (9,1), convtranspose=convtranspose)\n",
        "    self.VerticalDependencies = self._get_dependency_module(in_filters, hidden_filters, (1,9), convtranspose=convtranspose)\n",
        "    self.QuadrantDependencies = self._get_dependency_module(in_filters, hidden_filters, (3, 3), stride=3, convtranspose=convtranspose)\n",
        "\n",
        "    num_hidden = hidden_filters * 3\n",
        "    \n",
        "    self.Reduce = nn.Sequential(\n",
        "        nn.Conv2d(num_hidden, num_hidden, kernel_size=(3, 3), padding=1),\n",
        "        nn.Conv2d(num_hidden, out_filters, kernel_size=(1, 1)), # Look at each cell only, without neighbors; neighbors have already been considered.\n",
        "        nn.LeakyReLU()\n",
        "    )\n",
        "\n",
        "    self.Final = nn.LeakyReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    skip = self.skip(x)\n",
        "    x = self.initial_normalization(x)\n",
        "    horizontal_result = self.HorizontalDependencies(x)\n",
        "    vertical_result = self.VerticalDependencies(x)\n",
        "    quadrant_result = self.QuadrantDependencies(x)\n",
        "\n",
        "    combined = torch.cat((horizontal_result, vertical_result, quadrant_result), dim=1)\n",
        "\n",
        "    reduced = self.Reduce(combined)\n",
        "\n",
        "    residualized = reduced + skip\n",
        "    return self.Final(residualized)\n",
        "\n",
        "  def _get_dependency_module(self, in_filters, hidden_filters, kernel_size, stride=None, convtranspose=False):\n",
        "    if stride is None:\n",
        "      stride = 1\n",
        "      \n",
        "    if convtranspose:\n",
        "        return nn.Sequential(\n",
        "          nn.Conv2d(in_filters, hidden_filters*9, kernel_size=kernel_size, stride=stride),\n",
        "          nn.BatchNorm2d(hidden_filters*9),\n",
        "          nn.LeakyReLU(),\n",
        "          nn.ConvTranspose2d(hidden_filters*9, hidden_filters, kernel_size=kernel_size, stride=stride),\n",
        "          nn.BatchNorm2d(hidden_filters),\n",
        "          nn.Dropout(),\n",
        "          nn.LeakyReLU()\n",
        "      )\n",
        "    else:\n",
        "      return nn.Sequential(\n",
        "          nn.Conv2d(in_filters, hidden_filters, kernel_size=kernel_size, stride=stride),\n",
        "          nn.BatchNorm2d(hidden_filters),\n",
        "          nn.LeakyReLU(),\n",
        "          Reshape((-1, hidden_filters, 9)),\n",
        "          # Make into a full board shape that can be recombined... Maybe?\n",
        "          nn.Linear(9, 81), \n",
        "          nn.BatchNorm1d(hidden_filters),\n",
        "          nn.Dropout(),\n",
        "          Reshape((-1, hidden_filters, 9, 9)),\n",
        "          nn.LeakyReLU()\n",
        "      )\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG34hwOxnY74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MonoModel(nn.Module):\n",
        "  def __init__(self, solver_depth:int, convtranspose:bool=True, use_to_sudoku_range=True, growth_rate:Tuple[int]=(3,9)):\n",
        "    super(MonoModel, self).__init__()\n",
        "    if type(growth_rate) == int:\n",
        "      growth_base = 3\n",
        "      growth_frequency = growth_rate\n",
        "    else:\n",
        "      growth_base, growth_frequency = growth_rate\n",
        "    layer_numbers = [(growth_base**(i // growth_frequency + 2), growth_base**( (i+1) // growth_frequency + 2)) for i in range(solver_depth - 2)]\n",
        "    print(layer_numbers)\n",
        "    reducer_layer = layer_numbers[-1][1]\n",
        "    self.net = nn.Sequential(\n",
        "        SolverLayer(1, 9, 9, convtranspose=convtranspose),\n",
        "        *[ SolverLayer(i, i, o, convtranspose=convtranspose) for i, o in layer_numbers],\n",
        "        SolverLayer(reducer_layer, reducer_layer, 1, convtranspose=convtranspose),\n",
        "        Reshape((-1, 1, 9, 9)),\n",
        "        ToSudokuRange() if use_to_sudoku_range else nn.Identity()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3QgEnxzop79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StackedModel(nn.Module):\n",
        "  def __init__(self, solver_depth:int, convtranspose:bool=True, growth_rate:Tuple[int]=(3,9)):\n",
        "    super(StackedModel, self).__init__()\n",
        "    if type(growth_rate) == int:\n",
        "      growth_base = 3\n",
        "      growth_frequency = growth_rate\n",
        "    else:\n",
        "      growth_base, growth_frequency = growth_rate\n",
        "    layer_numbers = [(growth_base**(i // growth_frequency + 2), growth_base**( (i+1) // growth_frequency + 2)) for i in range(solver_depth - 1)]\n",
        "    print(layer_numbers)\n",
        "    reducer_layer = layer_numbers[-1][1]\n",
        "    self.net = nn.Sequential(\n",
        "        *[ SolverLayer(i, i, o, convtranspose=convtranspose) for i, o in layer_numbers],\n",
        "        SolverLayer(reducer_layer, reducer_layer, 9, convtranspose=convtranspose),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_A2vsv3q76T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def puzzle_exactifier(p):\n",
        "  return torch.round(p)\n",
        "\n",
        "\n",
        "\n",
        "def puzzle_masker(attempts, starting_puzzles):\n",
        "  assert attempts.size() == starting_puzzles.size()\n",
        "  num_filled_in_solution = torch.sum(starting_puzzles != 0).item()\n",
        "  attempts = torch.where(starting_puzzles == 0, attempts, starting_puzzles)\n",
        "  return (attempts, starting_puzzles, num_filled_in_solution)\n",
        "\n",
        "def solved_accuracy(attempts, solutions, starting_puzzles):\n",
        "  # print(f\"Puzzle Acc Before if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  if len(attempts.size()) == 4 and attempts.size(1) == 9:\n",
        "    attempts = stacked_to_mono(attempts).squeeze(1)\n",
        "    starting_puzzles = stacked_to_mono(starting_puzzles).squeeze(1)\n",
        "    solutions = solutions + 1\n",
        "  # print(f\"After if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  assert attempts.size() == solutions.size()\n",
        "  masked_puzzle, _, _ = puzzle_masker(attempts, starting_puzzles)\n",
        "  # print(masked_puzzle, solutions, starting_puzzles)\n",
        "  num_puzzles = attempts.size(0)\n",
        "  num_correct = (masked_puzzle.eq(solutions).sum(1).sum(1) == 9).sum().item()\n",
        "  # if num_correct > 0:\n",
        "    # print(\"\\n-Masked - \\n\", masked_puzzle, \"\\n- Solutions -\\n\", solutions)\n",
        "  return num_correct / num_puzzles\n",
        "\n",
        "def cell_accuracy(attempts, solutions, starting_puzzles):\n",
        "  # print(f\"Cell Acc Before if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  if len(attempts.size()) == 4 and attempts.size(1) == 9:\n",
        "    attempts = stacked_to_mono(attempts)\n",
        "    starting_puzzles = stacked_to_mono(starting_puzzles)\n",
        "    solutions = solutions + 1\n",
        "  # print(f\"After if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  assert attempts.size() == solutions.size()\n",
        "  masked_puzzle, _, num_filled = puzzle_masker(attempts, starting_puzzles)\n",
        "  print(\"\\nAttempts:\\n\", attempts, \"\\nMasked\\n\", masked_puzzle, \"\\nInitial\\n\", starting_puzzles, \"\\nSolution\\n\", solutions)\n",
        "  num_cells = attempts.numel()\n",
        "  print(f\"Comparison: \\n{masked_puzzle.eq(solutions)}\")\n",
        "  num_correct = masked_puzzle.eq(solutions).sum().item()\n",
        "  num_guessed_correctly = num_correct - num_filled\n",
        "  num_to_guess = num_cells - num_filled\n",
        "  # print(f\"--- {num_cells} - {num_correct} - {num_cells} - {num_filled} ---\")\n",
        "  return num_guessed_correctly / num_to_guess\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiPAmV3Eq5vi",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu-uveXztc8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_out(save_loc:str, model:MonoModel, **kargs):\n",
        "  if save_loc is None:\n",
        "    print(\"Skipping save, no save_loc provided.\")\n",
        "    return\n",
        "  else:\n",
        "    print(f\"Saving to {save_loc}\")\n",
        "  state = {\n",
        "      \"model\": model.state_dict()\n",
        "  }\n",
        "\n",
        "  for k, v in kargs.items():\n",
        "    state[k]=v\n",
        "  \n",
        "  torch.save(state, save_loc)\n",
        "\n",
        "def train(model:MonoModel,\n",
        "          criterion:torch.nn.modules.loss._Loss,\n",
        "          optimizer:torch.optim.Optimizer,\n",
        "          train_loader:DataLoader,\n",
        "          valid_loader:DataLoader,\n",
        "          num_epochs:int,\n",
        "          valid_frequency:int=5,\n",
        "          save_interval:int=1000,\n",
        "          mono=True,\n",
        "          save_loc:str=None):\n",
        "  loop = tqdm(total=num_epochs * len(train_loader) + (num_epochs // valid_frequency) * len(valid_loader), position=0)\n",
        "\n",
        "  # The loss of the last training and validation iteration, respectively.  \n",
        "  train_loss = None\n",
        "  valid_loss = None\n",
        "\n",
        "  # The puzzle accuracy of the last training and validation itersions. ( # puzzles right / # puzzles total )\n",
        "  train_accuracy = None\n",
        "  valid_accuracy = None\n",
        "\n",
        "  # The cell accuracy of the last training and validation iterations ( # filled cells right / # num fillable cells )\n",
        "  train_inner_acc = None\n",
        "  valid_inner_acc = None\n",
        "\n",
        "  tot_training_losses = []\n",
        "  tot_training_accuracies = []\n",
        "  tot_training_cell_accuracies = []\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "\n",
        "    training_losses = []\n",
        "    training_accuracies = []\n",
        "    training_cell_accuracies = []\n",
        "\n",
        "    loop.set_description(f\"[Training] Epoch: {e}. Loss: {valid_loss}/{train_loss}. Total Accuracy: {train_accuracy}/{valid_accuracy}. Inner Accuracy: {train_inner_acc}/{valid_inner_acc}\")\n",
        "\n",
        "    for i, (puzzle, solution) in enumerate(train_loader):\n",
        "      if mono:\n",
        "        puzzle, solution = puzzle.float().cuda(async=False), (solution.float() + 1).cuda(async=False).unsqueeze(1)\n",
        "      else:\n",
        "        puzzle, solution = puzzle.float().cuda(async=False), solution.long().cuda(async=False)\n",
        "\n",
        "      # print(f\"\\nPuzzle: {puzzle.size()}; solution: {solution.size()}\")\n",
        "      # initial_puzzle = puzzle.clone()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      attempt = model(puzzle)\n",
        "\n",
        "      if mono:\n",
        "        loss = criterion(attempt, solution)\n",
        "      else:\n",
        "        solution_in = solution.view(-1, 81)\n",
        "        attempt_in = attempt.view(-1, 9, 81)\n",
        "        loss = criterion(attempt_in, solution_in)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss = loss.item()\n",
        "      training_losses.append(train_loss)\n",
        "\n",
        "      # Compute accuracies\n",
        "      exactified = puzzle_exactifier(attempt)\n",
        "\n",
        "      solve_accuracy = solved_accuracy(exactified, solution, puzzle)\n",
        "      c_acc = cell_accuracy(exactified, solution, puzzle)\n",
        "\n",
        "      train_accuracy = solve_accuracy\n",
        "      training_accuracies.append(train_accuracy)\n",
        "\n",
        "      train_inner_acc = c_acc\n",
        "      training_cell_accuracies.append(train_inner_acc)\n",
        "\n",
        "      loop.set_description(f\"[Training] Epoch: {e}. Loss: {valid_loss}/{train_loss}. Total Accuracy: {valid_accuracy}/{train_accuracy}. Inner Accuracy: {train_inner_acc}/{valid_inner_acc}\")\n",
        "      loop.update()\n",
        "\n",
        "      if i % save_interval == 0:\n",
        "        tmp_losses = tot_training_losses + [training_losses]\n",
        "        tmp_game_accs = tot_training_accuracies + [training_accuracies]\n",
        "        tmp_cell_accs = tot_training_cell_accuracies + [training_cell_accuracies]\n",
        "        save_out(save_loc, model, train_loss=tmp_losses, train_game_accs=tmp_game_accs, train_cell_accs=tmp_cell_accs, epoch=e, iteration=i)\n",
        "    tot_training_losses.append(training_losses)\n",
        "    tot_training_accuracies.append(training_accuracies)\n",
        "    tot_training_cell_accuracies.append(training_cell_accuracies)\n",
        "    save_out(save_loc, model, train_loss=tot_training_losses, train_game_accs=tot_training_accuracies, train_cell_accs=tot_training_cell_accuracies, epoch=e, iteration=-1)\n",
        "  return model, tot_training_losses, tot_training_accuracies, tot_training_cell_accuracies\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRJwXojO6QGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MonoModel(solver_depth=5).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "train_loader = get_loader(root=\"/content/\", batch_size=3, mono=True, train=True, cap_train=5120)\n",
        "valid_loader = []\n",
        "num_epochs = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlGR35vHqScP",
        "colab_type": "code",
        "outputId": "5241c294-43fd-4ad9-d17f-2c3cc7b68991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model = StackedModel(solver_depth=5).cuda()\n",
        "train_loader = get_loader(root=\"/content/\", batch_size=3, mono=False, train=True, cap_train=5120)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 9), (9, 9)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftKIcRbg7BsZ",
        "colab_type": "code",
        "outputId": "1ade8dd5-b9b1-4be0-f09b-2a5fc367a01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "train(model, criterion, optimizer, train_loader, valid_loader, num_epochs, 1, mono=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training] Epoch: 0. Loss: None/6.698751449584961. Total Accuracy: None/0.0. Inner Accuracy: 0.15966386554621848/None:   2%|▏         | 78/5121 [00:04<04:39, 18.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-50b4b959e2e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-3e64461f0f4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, num_epochs, valid_frequency, save_interval, mono)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od6crIU6zAWk",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter Experiments\n",
        "* Things to test:\n",
        "  * Total parameters;\n",
        "  * depth of the network;\n",
        "  * increase in filter banks; \n",
        "  * One-hot output vs. continuous.\n",
        "  * Use sudoku range\n",
        "  * ConvTranspose upsampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an4PyxJ4mJuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tests = {\n",
        "    # \"mono_sd_11_linear_sudoku_range\": { \"mono\": True, \"sd\": 11, \"convtranspose\": False, \"sudoku_range\": True },\n",
        "    # \"mono_sd_11_convtran_sudoku_range\": { \"mono\": True, \"sd\": 11, \"convtranspose\": True, \"sudoku_range\": True },\n",
        "    # \"mono_sd_11_convtran\": { \"mono\": True, \"sd\": 11, \"convtranspose\": True, \"sudoku_range\": False },\n",
        "    # \"mono_sd_22_convtran\": { \"mono\": True, \"sd\": 22, \"convtranspose\": True, \"sudoku_range\": False },\n",
        "    # \"stacked_sd_11_convtran\": { \"mono\": False, \"sd\": 11, \"convtranspose\": True },\n",
        "    # \"stacked_sd_22_convtran\": { \"mono\": False, \"sd\": 22, \"convtranspose\": True },\n",
        "    # \"stacked_sd_18_convtran\": { \"mono\": False, \"sd\": 18, \"convtranspose\": True }\n",
        "    # \"stacked_sd_27_gr_3_26_convtran\": { \"mono\": False, \"sd\": 27, \"convtranspose\": True, \"growth_rate\": (3, 26) },\n",
        "    # \"stacked_sd_81_gr_3_80_convtran\": { \"mono\": False, \"sd\": 81, \"convtranspose\": True, \"growth_rate\": (3, 80) },\n",
        "    \"stacked_sd_11_gr_3_3_convtran\": { \"mono\": False, \"sd\": 15, \"convtranspose\": True, \"growth_rate\": (3, 3) },\n",
        "\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odye7eKF6h-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import path\n",
        "\n",
        "def save_test(key, **kargs):\n",
        "  f = \"/content/gdrive/My Drive/data/models/hyper_experiment.pickle\"\n",
        "  if path.exists(f):\n",
        "    existing = torch.load(f)\n",
        "  else:\n",
        "    existing = {}\n",
        "  existing[key] = kargs\n",
        "  torch.save(existing, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWD30Vmny_u3",
        "colab_type": "code",
        "outputId": "84060b69-d1bb-42bc-b091-32f93b065568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "epochs = 3\n",
        "cap_train = 1000000\n",
        "batch_size = 256\n",
        "\n",
        "for test in tests.keys():\n",
        "  params = tests[test]\n",
        "  mono = params[\"mono\"]\n",
        "  sd = params[\"sd\"]\n",
        "  convtranspose = params[\"convtranspose\"]\n",
        "  sudoku_range = params.get(\"sudoku_range\")\n",
        "  growth_rate = params.get(\"growth_rate\")\n",
        "  save_loc = f\"/content/gdrive/My Drive/data/models/HyperExp/{test}.mod\"\n",
        "\n",
        "\n",
        "  if mono:\n",
        "    model = MonoModel(solver_depth=sd, convtranspose=convtranspose, use_to_sudoku_range=sudoku_range, growth_rate=growth_rate).cuda()\n",
        "    criterion = nn.MSELoss()\n",
        "  else:\n",
        "    model = StackedModel(solver_depth=sd, convtranspose=convtranspose, growth_rate=growth_rate).cuda()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  print(f\"\\nTesting model {test} with {count_params(model)} parameters.\\n\")\n",
        "  train_loader = get_loader(root=\"/content/\", batch_size=batch_size, mono=mono, train=True, cap_train=cap_train)\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  valid_loader = []\n",
        "\n",
        "  \n",
        "  model, training_losses, game_accuracies, cell_accuracies = train(model,\n",
        "                                                                   criterion,\n",
        "                                                                   optimizer,\n",
        "                                                                   train_loader=train_loader,\n",
        "                                                                   valid_loader=valid_loader,\n",
        "                                                                   num_epochs=epochs,\n",
        "                                                                   valid_frequency=1,\n",
        "                                                                   save_interval=1000,\n",
        "                                                                   mono=mono,\n",
        "                                                                   save_loc=save_loc)\n",
        "  num_params = count_params(model)\n",
        "  save_test(test, model=model.state_dict(), training_losses=training_losses, game_accuracies=game_accuracies, cell_accuracies=cell_accuracies, num_params=num_params)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 27), (27, 27), (27, 27), (27, 81), (81, 81), (81, 81), (81, 243), (243, 243), (243, 243), (243, 729), (729, 729), (729, 729)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-39d4d14b2c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvtranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrowth_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrowth_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.90 GiB total capacity; 14.54 GiB already allocated; 7.69 MiB free; 15.19 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phRyY5aYQkaw",
        "colab_type": "code",
        "outputId": "353fbdf7-a367-4cdc-9607-44177f541c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "count_params(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1640034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI7IQOZ1Jtkp",
        "colab_type": "text"
      },
      "source": [
        "# Test Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CqXI9IGJvdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ec330504-4b17-441c-c547-e48b39ce7de7"
      },
      "source": [
        "model = StackedModel(solver_depth=15, convtranspose=True, growth_rate=(3, 4)).cuda()\n",
        "test = \"stacked_sd_11_gr_3_4_convtran\"\n",
        "state = torch.load(f\"/content/gdrive/My Drive/data/models/HyperExp/{test}.mod\")\n",
        "model.load_state_dict(state['model'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 9), (9, 27), (27, 27), (27, 27), (27, 27), (27, 81), (81, 81), (81, 81), (81, 81), (81, 243), (243, 243), (243, 243)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR9BYitiLdOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dl = get_loader('/content/', train=False, mono=False, batch_size=256, cap_train=25600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-FaGKAQLy2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from display import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpHWyBoaL1f1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "a06c5b1e-b4c2-4a40-839d-dff7bc99e511"
      },
      "source": [
        "tot = torch.zeros((9,9))\n",
        "num_solved = 0\n",
        "total_puzzles = 0\n",
        "loop = tqdm(total=len(dl), position=0)\n",
        "model = model.eval()\n",
        "with torch.no_grad():\n",
        "  for i, (puzzles, solutions) in zip(range(1009000), dl):\n",
        "    # print(f\"puzzles: {puzzles.size()}, Solutions: {solutions.size()}\")\n",
        "    puzzles, solutions = puzzles.float().cuda(), solutions.long().reshape(-1, 9,9)\n",
        "    attempts = stacked_to_mono(model(puzzles)).reshape(-1, 9,9).cpu()\n",
        "    # print(f\"Attempts: {attempts.size()}, Solutions: {solutions.size()}\")\n",
        "    for attempt, solution in zip(attempts, solutions):\n",
        "      total_puzzles += 1\n",
        "      differences = attempt.eq(solution + 1).cpu().long()\n",
        "      if differences.sum().item() == 81:\n",
        "        # print(f\"Solved puzzle: \\n{attempt}\\n{solution}\\n\")\n",
        "        num_solved += 1\n",
        "      # else:\n",
        "        # print(f\"Differend by {81 - differences.sum().item()}\")\n",
        "      # print(differences)\n",
        "      tot += differences * -1 + 1\n",
        "    loop.update(1)\n",
        "    # print(\"----- Attempt -----\")\n",
        "    # print_tensor_puzzle(attempt.reshape(9,9,9))\n",
        "    # print(\"----- Solution -----\")\n",
        "    # print(solution)\n",
        "    # print(f\"Cell Accuracy: {cell_accuracy(attempt, solution.cuda(), puzzle)}\\nGAme Accuracy: {solved_accuracy(attempt, solution.cuda(), puzzle)}\")\n",
        "print(f\"\\nSolved {num_solved} / {total_puzzles}\")\n",
        "print(tot)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [03:47<00:00,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Solved 8438 / 25600\n",
            "tensor([[705., 868., 611., 678., 793., 666., 595., 888., 689.],\n",
            "        [465., 521., 524., 565., 486., 573., 494., 467., 539.],\n",
            "        [618., 587., 569., 560., 546., 581., 547., 517., 633.],\n",
            "        [626., 883., 627., 647., 786., 676., 624., 847., 631.],\n",
            "        [584., 587., 594., 602., 518., 635., 502., 483., 601.],\n",
            "        [565., 577., 513., 571., 477., 560., 599., 484., 573.],\n",
            "        [625., 847., 653., 623., 858., 640., 571., 873., 645.],\n",
            "        [453., 502., 537., 516., 461., 623., 494., 447., 589.],\n",
            "        [606., 555., 511., 563., 504., 596., 560., 533., 609.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsrJjWVoV-M8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "12644cfd-7e10-4bcd-dab6-1c18c13d21a0"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "\n",
        "df_cm = pd.DataFrame(tot.view(9,9).numpy(), range(9), range(9))\n",
        "sn.heatmap(df_cm) # font size\n",
        "plt.show()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngjgBm5kV5P8DP4IFCE+Z1GwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NWd9hp_PGwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c236518-22b8-4400-e2ff-4c64b19048ab"
      },
      "source": [
        "ones = torch.ones((3, 3))\n",
        "mixed = torch.zeros((3,3))\n",
        "mixed[:,1] = 1\n",
        "ones.eq(mixed) * -1 + 1\n",
        "ones.eq(mixed).sum()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqpVKzym5yOc",
        "colab_type": "text"
      },
      "source": [
        "# TEST ACCURACY METRIC METHODS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz9yY8QE2g3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = torch.Tensor([[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "k = torch.Tensor([[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "l = torch.Tensor([[[2,2,2],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "\n",
        "z = torch.zeros((3,3,3))\n",
        "f = z.clone()\n",
        "f[:,:,0] = k[:,:,0]\n",
        "g = z.clone()\n",
        "g[:,:,0] = l[:,:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dBEcKsHdzK0D",
        "colab": {}
      },
      "source": [
        "s = torch.load(\"/content/gdrive/My Drive/data/models/MonoModel.mod\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d0bLtoj3zJGE",
        "colab": {}
      },
      "source": [
        "s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87tkJJpvJxd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s.keys()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJPKHXaQJzbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4_LhBgUJ7-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(s[\"model\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_vlhBSszTAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = get_loader(root=\"/content/\", batch_size=2, mono=True, train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am43RsYozZKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPss7Gt6zbTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n4JyYu0zb_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x, \"\\n\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqcrr41fzd-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(puzzle_exactifier(model(x.float().cuda())), \"\\n\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koaxWgD5zriX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz8EPwfR155A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWCX7vnu16-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MonoModel(solver_depth=21).cuda()\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTwLVmAWy0n5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = get_loader(\"/content/\", mono=False, batch_size=1, cap_train=10)\n",
        "dm = get_loader(\"/content/\", mono=True, batch_size=1, cap_train=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA6BZxUizyzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs, ys = next(iter(ds))\n",
        "xm, ym = next(iter(dm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osFKZIGVz6Df",
        "colab_type": "code",
        "outputId": "984cff15-0486-436d-d237-5fc1de04b0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "y = y + 1\n",
        "x,y = x.float().cuda(), y.float().cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2914cc4f3a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKLxg6A8xWa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = [dm.dataset.data.iloc[i].puzzle for i in range(10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZlNgvYd_c0z",
        "colab_type": "code",
        "outputId": "ee586d3f-c4a7-4152-bebf-511e0a8e3804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['070000043040009610800634900094052000358460020000800530080070091902100005007040802',\n",
              " '301086504046521070500000001400800002080347900009050038004090200008734090007208103',\n",
              " '048301560360008090910670003020000935509010200670020010004002107090100008150834029',\n",
              " '008317000004205109000040070327160904901450000045700800030001060872604000416070080',\n",
              " '040890630000136820800740519000467052450020700267010000520003400010280970004050063',\n",
              " '561092730020780090900005046600000427010070003073000819035900670700103080000000050',\n",
              " '310450900072986143906010508639178020150090806004003700005731009701829350000645010',\n",
              " '800134902041096080005070010008605000406310009023040860500709000010080040000401006',\n",
              " '165293004000001632023060090009175000500900018002030049098000006000000950000429381',\n",
              " '000003610000015007000008090086000700030800100500120309005060904060900530403701008']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78FtxyGOxk2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp = torch.Tensor([dm.dataset.to_mono_grid(i) for i in p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HARmy12KyKe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp = torch.Tensor([dm.dataset.to_stacked_grid(i) for i in p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwM6ZVXAzeKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp = torch.Tensor(sp)\n",
        "sp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEl4imJizf1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp.argmax(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OFy4J6Rzosa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "((sp.argmax(dim=0)) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vor7tw5RzqCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuqOPx4dz2g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYuTIZvQz7LY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am = sp.argmax(dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZrtGe9C268R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am_mask = torch.all(sp == 0, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRmayoz12_rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9W-sMyQ3A9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.where(am_mask, torch.zeros(am_mask.size()), am.float() + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpWMzjpJ3J_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "827VFlD23L9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model_util import stacked_to_mono"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihdZ3NmC4Alk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacked_to_mono(sp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_I097__4CU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbN_ZOGG4CwZ",
        "colab_type": "code",
        "outputId": "23f3fb64-8fdb-4c45-8567-2dcfbd4acaeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sp[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dut2Bn7n_m-n",
        "colab_type": "code",
        "outputId": "432c0859-429e-4848-9c34-372b30f8e07b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "mp[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 7., 0., 0., 0., 0., 0., 4., 3.],\n",
              "         [0., 4., 0., 0., 0., 9., 6., 1., 0.],\n",
              "         [8., 0., 0., 6., 3., 4., 9., 0., 0.],\n",
              "         [0., 9., 4., 0., 5., 2., 0., 0., 0.],\n",
              "         [3., 5., 8., 4., 6., 0., 0., 2., 0.],\n",
              "         [0., 0., 0., 8., 0., 0., 5., 3., 0.],\n",
              "         [0., 8., 0., 0., 7., 0., 0., 9., 1.],\n",
              "         [9., 0., 2., 1., 0., 0., 0., 0., 5.],\n",
              "         [0., 0., 7., 0., 4., 0., 8., 0., 2.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DrDF_5A_oZ-",
        "colab_type": "code",
        "outputId": "d6eb75be-91e2-4a14-accc-c5df7b9073bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "stacked_to_mono(sp)[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 7., 0., 0., 0., 0., 0., 4., 3.],\n",
              "        [0., 4., 0., 0., 0., 9., 6., 1., 0.],\n",
              "        [8., 0., 0., 6., 3., 4., 9., 0., 0.],\n",
              "        [0., 9., 4., 0., 5., 2., 0., 0., 0.],\n",
              "        [3., 5., 8., 4., 6., 0., 0., 2., 0.],\n",
              "        [0., 0., 0., 8., 0., 0., 5., 3., 0.],\n",
              "        [0., 8., 0., 0., 7., 0., 0., 9., 1.],\n",
              "        [9., 0., 2., 1., 0., 0., 0., 0., 5.],\n",
              "        [0., 0., 7., 0., 4., 0., 8., 0., 2.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m5_vXWQ_9DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stacked_to_mono_old(puzzles):\n",
        "    zeros_mask = torch.all(puzzles == 0, dim=1).cuda()\n",
        "    maxes = puzzles.argmax(dim=1).cuda()\n",
        "    return torch.where(zeros_mask, torch.zeros(zeros_mask.size()).cuda(), maxes.float().cuda() + 1).cuda().unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-evJNOU__uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translated = stacked_to_mono(sp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPQVYLktsRic",
        "colab_type": "code",
        "outputId": "aac25a83-6ab3-4ae6-ed2f-a7ef14421f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "translated.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5qeJBNVsTDZ",
        "colab_type": "code",
        "outputId": "7fede6f4-175d-41bf-ca1d-a3e4123af278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "mp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNG0Ng14sUrI",
        "colab_type": "code",
        "outputId": "be4623d4-b43f-47ef-b431-8c3b0cc8b25d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "translated.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uQ-HEwxseOC",
        "colab_type": "code",
        "outputId": "ddf33d63-6e22-4762-f485-a7f36ba61dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.all(mp == translated)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Expy3u1Uska5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}