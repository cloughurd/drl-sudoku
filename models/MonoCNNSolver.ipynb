{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "TestLoader.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW6VWCHjm-g6",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tMQ3_yDj_md",
        "colab_type": "code",
        "outputId": "0e95e932-efce-4780-eec2-7061ea3f23d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp /content/gdrive/My\\ Drive/data/*.zip .\n",
        "!unzip /content/sudoku.zip\n",
        "!mkdir /content/test\n",
        "!unzip /content/sudoku_test.zip -d /content/test\n",
        "!mv /content/test/sudoku.csv /content/sudoku_test.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Archive:  /content/sudoku.zip\n",
            "  inflating: sudoku.csv              \n",
            "Archive:  /content/sudoku_test.zip\n",
            "  inflating: /content/test/sudoku.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cghus0djA4Q",
        "colab_type": "code",
        "outputId": "de01f7c2-54ad-4ca7-a078-69820bf16d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!rm -rf drl-sudoku\n",
        "!git clone https://github.com/cloughurd/drl-sudoku.git\n",
        "!mv drl-sudoku/data/* ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'drl-sudoku'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 147 (delta 86), reused 64 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (147/147), 301.09 KiB | 3.31 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaIypeXinqFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import math\n",
        "import contextlib\n",
        "from typing import List\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from model_util import stacked_to_mono\n",
        "\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFMABO1nnB7f",
        "colab_type": "text"
      },
      "source": [
        "# Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxiPBreTi7Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dataloader import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqQdT8QAnZXa",
        "colab_type": "text"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1WF_WlwqVlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super(Reshape, self).__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJM42t58rc79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToSudokuRange(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ToSudokuRange, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.net = lambda x: (9 * self.sigmoid(x)) + 0.5\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MecL5K3ielK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SolverLayer(nn.Module):\n",
        "  def __init__(self, in_filters:int, hidden_filters:int, out_filters:int):\n",
        "    super(SolverLayer, self).__init__()\n",
        "\n",
        "    if in_filters != out_filters:\n",
        "      self.skip = nn.Conv2d(in_filters, out_filters, kernel_size=1)\n",
        "    else:\n",
        "      self.skip = nn.Identity()\n",
        "\n",
        "    self.initial_normalization = nn.InstanceNorm2d(in_filters) # Normalize every individual game within its filters. Not positive this is a good idea... maybe use the 3d version?\n",
        "\n",
        "    self.HorizontalDependencies = nn.Sequential(        \n",
        "        nn.Conv2d(in_filters, hidden_filters, kernel_size=(9, 1)), # Output is 1, 9.\n",
        "        nn.BatchNorm2d(hidden_filters),\n",
        "        nn.LeakyReLU(),\n",
        "        Reshape((-1, hidden_filters, 9)),\n",
        "        # Make into a full board shape that can be recombined... Maybe?\n",
        "        nn.Linear(9, 81),\n",
        "        nn.BatchNorm1d(hidden_filters),\n",
        "        nn.Dropout(),\n",
        "        Reshape((-1, hidden_filters, 9, 9)),\n",
        "        nn.LeakyReLU()\n",
        "    )\n",
        "\n",
        "    self.VerticalDependencies = nn.Sequential(\n",
        "        nn.Conv2d(in_filters, hidden_filters, kernel_size=(1, 9)), # Output is 9, 1.\n",
        "        nn.BatchNorm2d(hidden_filters),\n",
        "        nn.LeakyReLU(),\n",
        "        Reshape((-1, hidden_filters, 9)),\n",
        "        # Make into a full board shape that can be recombined... Maybe?\n",
        "        nn.Linear(9, 81), \n",
        "        nn.BatchNorm1d(hidden_filters),\n",
        "        nn.Dropout(),\n",
        "        Reshape((-1, hidden_filters, 9, 9)),\n",
        "        nn.LeakyReLU()\n",
        "    )\n",
        "\n",
        "    self.QuadrantDependencies = nn.Sequential(\n",
        "        nn.Conv2d(in_filters, hidden_filters, kernel_size=(3, 3), stride=3),\n",
        "        nn.BatchNorm2d(hidden_filters),\n",
        "        nn.LeakyReLU(),\n",
        "        Reshape((-1, hidden_filters, 9)),\n",
        "        # Make into a full board shape that can be recombined... Maybe?\n",
        "        nn.Linear(9, 81), \n",
        "        nn.BatchNorm1d(hidden_filters),\n",
        "        nn.Dropout(),\n",
        "        Reshape((-1, hidden_filters, 9, 9)),\n",
        "        nn.LeakyReLU()\n",
        "    )\n",
        "\n",
        "    self.Reduce = nn.Sequential(\n",
        "        nn.Conv2d(hidden_filters * 3, hidden_filters*3, kernel_size=(3, 3), padding=1),\n",
        "        nn.Conv2d(hidden_filters * 3, out_filters, kernel_size=(1, 1)), # Look at each cell only, without neighbors; neighbors have already been considered.\n",
        "        nn.LeakyReLU()\n",
        "    )\n",
        "\n",
        "    self.Final = nn.LeakyReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    skip = self.skip(x)\n",
        "    x = self.initial_normalization(x)\n",
        "    horizontal_result = self.HorizontalDependencies(x)\n",
        "    vertical_result = self.VerticalDependencies(x)\n",
        "    quadrant_result = self.QuadrantDependencies(x)\n",
        "\n",
        "    combined = torch.cat((horizontal_result, vertical_result, quadrant_result), dim=1)\n",
        "\n",
        "    reduced = self.Reduce(combined)\n",
        "\n",
        "    residualized = reduced + skip\n",
        "    return self.Final(residualized)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG34hwOxnY74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MonoModel(nn.Module):\n",
        "  def __init__(self, solver_depth:int):\n",
        "    super(MonoModel, self).__init__()\n",
        "    layer_numbers = [(3**(i // 9 + 2), 3**( (i+1) // 9 + 2)) for i in range(solver_depth - 2)]\n",
        "    print(layer_numbers)\n",
        "    reducer_layer = layer_numbers[-1][1]\n",
        "    self.net = nn.Sequential(\n",
        "        SolverLayer(1, 9, 9),\n",
        "        *[ SolverLayer(i, i, o) for i, o in layer_numbers],\n",
        "        SolverLayer(reducer_layer, reducer_layer, 1),\n",
        "        Reshape((-1, 1, 9, 9)),\n",
        "        ToSudokuRange()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3QgEnxzop79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StackedModel(nn.Module):\n",
        "  def __init__(self, solver_depth:int):\n",
        "    super(StackedModel, self).__init__()\n",
        "    layer_numbers = [(3**(i // 9 + 2), 3**( (i+1) // 9 + 2)) for i in range(solver_depth - 1)]\n",
        "    print(layer_numbers)\n",
        "    reducer_layer = layer_numbers[-1][1]\n",
        "    self.net = nn.Sequential(\n",
        "        *[ SolverLayer(i, i, o) for i, o in layer_numbers],\n",
        "        SolverLayer(reducer_layer, reducer_layer, 9),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_A2vsv3q76T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def puzzle_exactifier(p):\n",
        "  return torch.round(p)\n",
        "\n",
        "\n",
        "\n",
        "def puzzle_masker(attempts, starting_puzzles):\n",
        "  assert attempts.size() == starting_puzzles.size()\n",
        "  num_filled_in_solution = torch.sum(starting_puzzles != 0).item()\n",
        "  attempts = torch.where(starting_puzzles == 0, attempts, starting_puzzles)\n",
        "  return (attempts, starting_puzzles, num_filled_in_solution)\n",
        "\n",
        "def solved_accuracy(attempts, solutions, starting_puzzles):\n",
        "  # print(f\"Puzzle Acc Before if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  if len(attempts.size()) == 4 and attempts.size(1) == 9:\n",
        "    attempts = stacked_to_mono(attempts).squeeze(1)\n",
        "    starting_puzzles = stacked_to_mono(starting_puzzles).squeeze(1)\n",
        "    solutions = solutions + 1\n",
        "  # print(f\"After if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  assert attempts.size() == solutions.size()\n",
        "  masked_puzzle, _, _ = puzzle_masker(attempts, starting_puzzles)\n",
        "  # print(masked_puzzle, solutions, starting_puzzles)\n",
        "  num_puzzles = attempts.size(0)\n",
        "  num_correct = (masked_puzzle.eq(solutions).sum(1).sum(1) == 9).sum().item()\n",
        "  # if num_correct > 0:\n",
        "    # print(\"\\n-Masked - \\n\", masked_puzzle, \"\\n- Solutions -\\n\", solutions)\n",
        "  return num_correct / num_puzzles\n",
        "\n",
        "def cell_accuracy(attempts, solutions, starting_puzzles):\n",
        "  # print(f\"Cell Acc Before if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  if len(attempts.size()) == 4 and attempts.size(1) == 9:\n",
        "    attempts = stacked_to_mono(attempts)\n",
        "    starting_puzzles = stacked_to_mono(starting_puzzles)\n",
        "    solutions = solutions + 1\n",
        "  # print(f\"After if {attempts.size()} | {solutions.size()} | {starting_puzzles.size()}\")\n",
        "  assert attempts.size() == solutions.size()\n",
        "  masked_puzzle, _, num_filled = puzzle_masker(attempts, starting_puzzles)\n",
        "  # print(\"\\nAttempts:\\n\", attempts, \"\\nMasked\\n\", masked_puzzle, \"\\nInitial\\n\", starting_puzzles, \"\\nSolution\\n\", solutions)\n",
        "  num_cells = attempts.numel()\n",
        "  num_correct = masked_puzzle.eq(solutions).sum().item()\n",
        "  num_guessed_correctly = num_correct - num_filled\n",
        "  num_to_guess = num_cells - num_filled\n",
        "  # print(f\"--- {num_cells} - {num_correct} - {num_cells} - {num_filled} ---\")\n",
        "  return num_guessed_correctly / num_to_guess\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiPAmV3Eq5vi",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu-uveXztc8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_out(model:MonoModel, **kargs):\n",
        "  state = {\n",
        "      \"model\": model.state_dict()\n",
        "  }\n",
        "\n",
        "  for k, v in kargs.items():\n",
        "    state[k]=v\n",
        "  \n",
        "  torch.save(state, \"/content/gdrive/My Drive/data/models/MonoModel_Test.mod\")\n",
        "\n",
        "def train(model:MonoModel,\n",
        "          criterion:torch.nn.modules.loss._Loss,\n",
        "          optimizer:torch.optim.Optimizer,\n",
        "          train_loader:DataLoader,\n",
        "          valid_loader:DataLoader,\n",
        "          num_epochs:int,\n",
        "          valid_frequency:int=5,\n",
        "          save_interval:int=1000,\n",
        "          mono=True):\n",
        "  loop = tqdm(total=num_epochs * len(train_loader) + (num_epochs // valid_frequency) * len(valid_loader), position=0)\n",
        "\n",
        "  # The loss of the last training and validation iteration, respectively.  \n",
        "  train_loss = None\n",
        "  valid_loss = None\n",
        "\n",
        "  # The puzzle accuracy of the last training and validation itersions. ( # puzzles right / # puzzles total )\n",
        "  train_accuracy = None\n",
        "  valid_accuracy = None\n",
        "\n",
        "  # The cell accuracy of the last training and validation iterations ( # filled cells right / # num fillable cells )\n",
        "  train_inner_acc = None\n",
        "  valid_inner_acc = None\n",
        "\n",
        "  tot_training_losses = []\n",
        "  tot_training_accuracies = []\n",
        "  tot_training_cell_accuracies = []\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "\n",
        "    training_losses = []\n",
        "    training_accuracies = []\n",
        "    training_cell_accuracies = []\n",
        "\n",
        "    loop.set_description(f\"[Training] Epoch: {e}. Loss: {valid_loss}/{train_loss}. Total Accuracy: {train_accuracy}/{valid_accuracy}. Inner Accuracy: {train_inner_acc}/{valid_inner_acc}\")\n",
        "\n",
        "    for i, (puzzle, solution) in enumerate(train_loader):\n",
        "      if mono:\n",
        "        puzzle, solution = puzzle.float().cuda(async=False), (solution.float() + 1).cuda(async=False).unsqueeze(1)\n",
        "      else:\n",
        "        puzzle, solution = puzzle.float().cuda(async=False), solution.long().cuda(async=False)\n",
        "\n",
        "      # print(f\"\\nPuzzle: {puzzle.size()}; solution: {solution.size()}\")\n",
        "      # initial_puzzle = puzzle.clone()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      attempt = model(puzzle)\n",
        "\n",
        "      if mono:\n",
        "        loss = criterion(attempt, solution)\n",
        "      else:\n",
        "        solution_in = solution.view(-1, 81)\n",
        "        attempt_in = attempt.view(-1, 9, 81)\n",
        "        loss = criterion(attempt_in, solution_in)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss = loss.item()\n",
        "      training_losses.append(train_loss)\n",
        "\n",
        "      # Compute accuracies\n",
        "      exactified = puzzle_exactifier(attempt)\n",
        "\n",
        "      solve_accuracy = solved_accuracy(exactified, solution, puzzle)\n",
        "      c_acc = cell_accuracy(exactified, solution, puzzle)\n",
        "\n",
        "      train_accuracy = solve_accuracy\n",
        "      training_accuracies.append(train_accuracy)\n",
        "\n",
        "      train_inner_acc = c_acc\n",
        "      training_cell_accuracies.append(train_inner_acc)\n",
        "\n",
        "      loop.set_description(f\"[Training] Epoch: {e}. Loss: {valid_loss}/{train_loss}. Total Accuracy: {valid_accuracy}/{train_accuracy}. Inner Accuracy: {train_inner_acc}/{valid_inner_acc}\")\n",
        "      loop.update()\n",
        "\n",
        "      if i % save_interval == 0:\n",
        "        tmp_losses = tot_training_losses + [training_losses]\n",
        "        tmp_game_accs = tot_training_accuracies + [training_accuracies]\n",
        "        tmp_cell_accs = tot_training_cell_accuracies + [training_cell_accuracies]\n",
        "        save_out(model, train_loss=tmp_losses, train_game_accs=tmp_game_accs, train_cell_accs=tmp_cell_accs, epoch=e, iteration=i)\n",
        "    tot_training_losses.append(training_losses)\n",
        "    tot_training_accuracies.append(training_accuracies)\n",
        "    tot_training_cell_accuracies.append(training_cell_accuracies)\n",
        "    save_out(model, train_loss=tot_training_losses, train_game_accs=tot_training_accuracies, train_cell_accs=tot_training_cell_accuracies, epoch=e, iteration=-1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRJwXojO6QGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20329128-34da-4f38-ac32-069e12690cfa"
      },
      "source": [
        "model = MonoModel(solver_depth=5).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "train_loader = get_loader(root=\"/content/\", batch_size=3, mono=True, train=True, cap_train=5120)\n",
        "valid_loader = []\n",
        "num_epochs = 3"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 9)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlGR35vHqScP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5241c294-43fd-4ad9-d17f-2c3cc7b68991"
      },
      "source": [
        "model = StackedModel(solver_depth=5).cuda()\n",
        "train_loader = get_loader(root=\"/content/\", batch_size=3, mono=False, train=True, cap_train=5120)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(9, 9), (9, 9), (9, 9), (9, 9)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftKIcRbg7BsZ",
        "colab_type": "code",
        "outputId": "1ade8dd5-b9b1-4be0-f09b-2a5fc367a01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "train(model, criterion, optimizer, train_loader, valid_loader, num_epochs, 1, mono=True)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training] Epoch: 0. Loss: None/6.698751449584961. Total Accuracy: None/0.0. Inner Accuracy: 0.15966386554621848/None:   2%|▏         | 78/5121 [00:04<04:39, 18.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-50b4b959e2e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-3e64461f0f4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, num_epochs, valid_frequency, save_interval, mono)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an4PyxJ4mJuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Things to test:\n",
        "#   Total parameters;\n",
        "#   depth of the network;\n",
        "#   increase in filter banks; \n",
        "#   One-hot output vs. continuous."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqpVKzym5yOc",
        "colab_type": "text"
      },
      "source": [
        "# TEST ACCURACY METRIC METHODS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz9yY8QE2g3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = torch.Tensor([[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "k = torch.Tensor([[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "l = torch.Tensor([[[2,2,2],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]])\n",
        "\n",
        "z = torch.zeros((3,3,3))\n",
        "f = z.clone()\n",
        "f[:,:,0] = k[:,:,0]\n",
        "g = z.clone()\n",
        "g[:,:,0] = l[:,:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dBEcKsHdzK0D",
        "colab": {}
      },
      "source": [
        "s = torch.load(\"/content/gdrive/My Drive/data/models/MonoModel.mod\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d0bLtoj3zJGE",
        "colab": {}
      },
      "source": [
        "s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87tkJJpvJxd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s.keys()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJPKHXaQJzbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4_LhBgUJ7-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(s[\"model\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_vlhBSszTAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = get_loader(root=\"/content/\", batch_size=2, mono=True, train=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am43RsYozZKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPss7Gt6zbTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n4JyYu0zb_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x, \"\\n\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqcrr41fzd-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(puzzle_exactifier(model(x.float().cuda())), \"\\n\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koaxWgD5zriX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz8EPwfR155A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWCX7vnu16-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MonoModel(solver_depth=21).cuda()\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTwLVmAWy0n5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = get_loader(\"/content/\", mono=False, batch_size=1, cap_train=10)\n",
        "dm = get_loader(\"/content/\", mono=True, batch_size=1, cap_train=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA6BZxUizyzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs, ys = next(iter(ds))\n",
        "xm, ym = next(iter(dm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osFKZIGVz6Df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "984cff15-0486-436d-d237-5fc1de04b0ee"
      },
      "source": [
        "y = y + 1\n",
        "x,y = x.float().cuda(), y.float().cuda()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2914cc4f3a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKLxg6A8xWa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = [dm.dataset.data.iloc[i].puzzle for i in range(10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZlNgvYd_c0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "ee586d3f-c4a7-4152-bebf-511e0a8e3804"
      },
      "source": [
        "p"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['070000043040009610800634900094052000358460020000800530080070091902100005007040802',\n",
              " '301086504046521070500000001400800002080347900009050038004090200008734090007208103',\n",
              " '048301560360008090910670003020000935509010200670020010004002107090100008150834029',\n",
              " '008317000004205109000040070327160904901450000045700800030001060872604000416070080',\n",
              " '040890630000136820800740519000467052450020700267010000520003400010280970004050063',\n",
              " '561092730020780090900005046600000427010070003073000819035900670700103080000000050',\n",
              " '310450900072986143906010508639178020150090806004003700005731009701829350000645010',\n",
              " '800134902041096080005070010008605000406310009023040860500709000010080040000401006',\n",
              " '165293004000001632023060090009175000500900018002030049098000006000000950000429381',\n",
              " '000003610000015007000008090086000700030800100500120309005060904060900530403701008']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78FtxyGOxk2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp = torch.Tensor([dm.dataset.to_mono_grid(i) for i in p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HARmy12KyKe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp = torch.Tensor([dm.dataset.to_stacked_grid(i) for i in p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwM6ZVXAzeKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp = torch.Tensor(sp)\n",
        "sp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEl4imJizf1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp.argmax(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OFy4J6Rzosa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "((sp.argmax(dim=0)) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vor7tw5RzqCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuqOPx4dz2g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYuTIZvQz7LY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am = sp.argmax(dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZrtGe9C268R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am_mask = torch.all(sp == 0, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRmayoz12_rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "am_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9W-sMyQ3A9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.where(am_mask, torch.zeros(am_mask.size()), am.float() + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpWMzjpJ3J_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "827VFlD23L9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model_util import stacked_to_mono"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihdZ3NmC4Alk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacked_to_mono(sp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_I097__4CU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbN_ZOGG4CwZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23f3fb64-8fdb-4c45-8567-2dcfbd4acaeb"
      },
      "source": [
        "sp[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dut2Bn7n_m-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "432c0859-429e-4848-9c34-372b30f8e07b"
      },
      "source": [
        "mp[0]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 7., 0., 0., 0., 0., 0., 4., 3.],\n",
              "         [0., 4., 0., 0., 0., 9., 6., 1., 0.],\n",
              "         [8., 0., 0., 6., 3., 4., 9., 0., 0.],\n",
              "         [0., 9., 4., 0., 5., 2., 0., 0., 0.],\n",
              "         [3., 5., 8., 4., 6., 0., 0., 2., 0.],\n",
              "         [0., 0., 0., 8., 0., 0., 5., 3., 0.],\n",
              "         [0., 8., 0., 0., 7., 0., 0., 9., 1.],\n",
              "         [9., 0., 2., 1., 0., 0., 0., 0., 5.],\n",
              "         [0., 0., 7., 0., 4., 0., 8., 0., 2.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DrDF_5A_oZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "d6eb75be-91e2-4a14-accc-c5df7b9073bf"
      },
      "source": [
        "stacked_to_mono(sp)[0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 7., 0., 0., 0., 0., 0., 4., 3.],\n",
              "        [0., 4., 0., 0., 0., 9., 6., 1., 0.],\n",
              "        [8., 0., 0., 6., 3., 4., 9., 0., 0.],\n",
              "        [0., 9., 4., 0., 5., 2., 0., 0., 0.],\n",
              "        [3., 5., 8., 4., 6., 0., 0., 2., 0.],\n",
              "        [0., 0., 0., 8., 0., 0., 5., 3., 0.],\n",
              "        [0., 8., 0., 0., 7., 0., 0., 9., 1.],\n",
              "        [9., 0., 2., 1., 0., 0., 0., 0., 5.],\n",
              "        [0., 0., 7., 0., 4., 0., 8., 0., 2.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m5_vXWQ_9DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stacked_to_mono_old(puzzles):\n",
        "    zeros_mask = torch.all(puzzles == 0, dim=1).cuda()\n",
        "    maxes = puzzles.argmax(dim=1).cuda()\n",
        "    return torch.where(zeros_mask, torch.zeros(zeros_mask.size()).cuda(), maxes.float().cuda() + 1).cuda().unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-evJNOU__uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translated = stacked_to_mono(sp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPQVYLktsRic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aac25a83-6ab3-4ae6-ed2f-a7ef14421f2b"
      },
      "source": [
        "translated.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5qeJBNVsTDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7fede6f4-175d-41bf-ca1d-a3e4123af278"
      },
      "source": [
        "mp.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNG0Ng14sUrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "be4623d4-b43f-47ef-b431-8c3b0cc8b25d"
      },
      "source": [
        "translated.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1, 9, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uQ-HEwxseOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ddf33d63-6e22-4762-f485-a7f36ba61dce"
      },
      "source": [
        "torch.all(mp == translated)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Expy3u1Uska5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}